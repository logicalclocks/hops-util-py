{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `hops-util-py` Integration Tests\n",
    "\n",
    "This notebook can be converted to a python file and submitted as a spark job for integration tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>62</td><td>application_1582118837056_0052</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-22-206.eu-north-1.compute.internal:8088/proxy/application_1582118837056_0052/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-22-206.eu-north-1.compute.internal:8042/node/containerlogs/container_e02_1582118837056_0052_01_000001/ittests__fabio000\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])"
     ]
    }
   ],
   "source": [
    "from hops import experiment, hdfs, tensorboard, devices, kafka, featurestore, tls, util, serving, model, constants\n",
    "from hops.experiment import Direction\n",
    "from hops.model import Metric\n",
    "import stat\n",
    "import os\n",
    "import shutil\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, LongType, IntegerType, FloatType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "from pyspark.sql import DataFrame\n",
    "from petastorm.unischema import dict_to_spark_row, Unischema, UnischemaField\n",
    "from petastorm.codecs import ScalarCodec, CompressedImageCodec, NdarrayCodec\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "from pyspark.sql import SparkSession\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import random\n",
    "from confluent_kafka import Producer, Consumer, KafkaError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment API Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_asserts():\n",
    "    from hops import tensorboard\n",
    "    from hops import devices\n",
    "    from hops import hdfs\n",
    "    import os\n",
    "    assert tensorboard.logdir() != None\n",
    "    assert devices.get_num_gpus() == 0\n",
    "    assert hdfs.project_path() == hdfs.project_path(hdfs.project_name())\n",
    "    if tensorboard.local_logdir_bool:\n",
    "        assert \"hdfs://\" not in tensorboard.logdir()\n",
    "        assert os.path.exists(tensorboard.logdir())\n",
    "    else:\n",
    "        assert \"hdfs://\" in tensorboard.logdir()\n",
    "        assert hdfs.exists(tensorboard.logdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_ret():\n",
    "    exp_asserts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_ret_params(a, b):\n",
    "    exp_asserts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_raw_value():\n",
    "    exp_asserts()\n",
    "    return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_raw_value_params(a, b):\n",
    "    exp_asserts()\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_path():\n",
    "    exp_asserts()\n",
    "    f = open('testfile.txt', 'w')\n",
    "    f.write('stuff happened')\n",
    "    f.close()\n",
    "    return {'logfile': 'testfile.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_path_params(a, b):\n",
    "    exp_asserts()\n",
    "    f = open('testfile.txt', 'w')\n",
    "    f.write('stuff happened')\n",
    "    f.close()\n",
    "    return {'logfile': 'testfile.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_val():\n",
    "    exp_asserts()\n",
    "    return {'value': -10.3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ret_val_params(a, b):\n",
    "    exp_asserts()\n",
    "    return {'value': a+b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_ret():\n",
    "    exp_asserts()\n",
    "    f = open('testfile.txt', 'w')\n",
    "    f.write('stuff happened')\n",
    "    f.close()\n",
    "    return {'value': 10, 'morevals': 0.5, 'logfile': 'testfile.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_ret_params(a, b):\n",
    "    exp_asserts()\n",
    "    f = open('testfile.txt', 'w')\n",
    "    f.write('stuff happened')\n",
    "    f.close()\n",
    "    return {'value': a+b, 'morevals': b, 'logfile': 'testfile.txt', 'diagram': 'img.png'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_in_tensorboard_logdir():\n",
    "    from hops import tensorboard\n",
    "    from hops import hdfs\n",
    "    import os\n",
    "    import uuid\n",
    "    model_name = str(uuid.uuid4())\n",
    "    \n",
    "    if tensorboard.logdir():\n",
    "        if os.path.exists(tensorboard.logdir()):\n",
    "            os.mkdir(tensorboard.logdir() + '/model')\n",
    "            f = open(tensorboard.logdir() + '/model/model.pb', 'w')\n",
    "            f.write('model')\n",
    "            f.close()\n",
    "        else:\n",
    "            hdfs.mkdir(tensorboard.logdir() + '/model')\n",
    "            hdfs.dump(\"model\", tensorboard.logdir() + '/model/model.pb')\n",
    "    \n",
    "    return {'name': model_name}\n",
    "\n",
    "def create_model_in_tensorboard_logdir_params(a, b):\n",
    "    from hops import tensorboard\n",
    "    from hops import hdfs\n",
    "    import os\n",
    "    import uuid\n",
    "    model_name = str(uuid.uuid4())\n",
    "    model_path = tensorboard.logdir() + '/model/' + model_name\n",
    "    \n",
    "    #create a 'model'\n",
    "    if tensorboard.logdir():\n",
    "        if os.path.exists(tensorboard.logdir()):\n",
    "            os.mkdir(tensorboard.logdir() + '/model')\n",
    "            f = open(tensorboard.logdir() + '/model/model.pb', 'w')\n",
    "            f.write('model')\n",
    "            f.close()\n",
    "        else:\n",
    "            hdfs.mkdir(tensorboard.logdir() + '/model')\n",
    "            hdfs.dump(\"model\", tensorboard.logdir() + '/model/model.pb')\n",
    "    \n",
    "    return {'name': model_name, 'optval': a+b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model_in_wrapper():\n",
    "    ret_dict = create_model_in_tensorboard_logdir()\n",
    "    from hops import model\n",
    "    from hops import tensorboard\n",
    "    if tensorboard.logdir():\n",
    "        model.export(tensorboard.logdir() + '/model', ret_dict['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_return_values(logdir, hp_dict, should_return_hp_dict, return_dict, should_return_return_dict):\n",
    "    assert hdfs.exists(logdir)\n",
    "    \n",
    "    if should_return_hp_dict:\n",
    "        print('Asserting hp_dict {} is a dict'.format(hp_dict))\n",
    "        assert type(hp_dict) == dict\n",
    "    else:\n",
    "        assert not hp_dict\n",
    "        \n",
    "    if should_return_return_dict:\n",
    "        print('Asserting return_dict {} is a dict'.format(return_dict))\n",
    "        assert type(return_dict) == dict    \n",
    "    else:\n",
    "        assert not return_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test `experiment.launch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'log': 'Experiments/application_1576760828949_0042_1/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "params={'a': [-5, 4.9], 'b': [-8, 10.3]}\n",
    "\n",
    "logdir, return_dict = experiment.launch(no_ret, local_logdir=False, name='no ret')\n",
    "assert_return_values(logdir, None, False, return_dict, True)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'log': 'Experiments/application_1576760828949_0042_2/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(no_ret, local_logdir=True, name='no ret')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(no_ret_params, params, local_logdir=True, name='no ret params')\n",
    "assert_return_values(logdir, None, False, return_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(no_ret_params, params, local_logdir=False, name='no ret params')\n",
    "assert_return_values(logdir, None, False, return_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'metric': 10, 'log': 'Experiments/application_1576760828949_0042_5/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_raw_value, local_logdir=False, name='single ret raw value')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'metric': 10, 'log': 'Experiments/application_1576760828949_0042_6/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_raw_value, local_logdir=True, name='single ret raw value')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_raw_value_params, params, local_logdir=True, name='single ret raw value params')\n",
    "assert_return_values(logdir, None, False, return_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_raw_value_params, params, local_logdir=False, name='single ret raw value params')\n",
    "assert_return_values(logdir, None, False, return_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'logfile': 'Experiments/application_1576760828949_0042_9/testfile.txt', 'log': 'Experiments/application_1576760828949_0042_9/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_path, local_logdir=False, description='some custom desc', name='single ret path')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'logfile': 'Experiments/application_1576760828949_0042_10/testfile.txt', 'log': 'Experiments/application_1576760828949_0042_10/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_path, local_logdir=True, name='single ret path')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_path_params, params, local_logdir=True, name='single ret path params')\n",
    "assert_return_values(logdir, None, False, return_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_path_params, params, local_logdir=False, name='single ret path params')\n",
    "assert_return_values(logdir, None, False, return_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'value': -10.3, 'log': 'Experiments/application_1576760828949_0042_13/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_val, local_logdir=False, name='single ret val', description='some custom desc')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'value': -10.3, 'log': 'Experiments/application_1576760828949_0042_14/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_val, local_logdir=True, name='single ret val')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_val_params, params, local_logdir=True, name='single ret val params')\n",
    "assert_return_values(logdir, None, False, return_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(single_ret_val_params, params, local_logdir=False, name='single ret val params')\n",
    "assert_return_values(logdir, None, False, return_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'value': 10, 'morevals': 0.5, 'logfile': 'Experiments/application_1576760828949_0042_17/testfile.txt', 'log': 'Experiments/application_1576760828949_0042_17/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(multi_ret, local_logdir=False, name='multi ret', metric_key='value')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'value': 10, 'morevals': 0.5, 'logfile': 'Experiments/application_1576760828949_0042_18/testfile.txt', 'log': 'Experiments/application_1576760828949_0042_18/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(multi_ret, local_logdir=True, name='multi ret', metric_key='morevals')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(multi_ret_params, params, local_logdir=False, name='multi ret params')\n",
    "assert_return_values(logdir, None, False, return_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(multi_ret_params, params, local_logdir=True, name='multi ret params')\n",
    "assert_return_values(logdir, None, False, return_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'metric': -13, 'log': 'Experiments/application_1576760828949_0042_21/a=-5&b=-8/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "params={'a': [-5], 'b': [-8]}\n",
    "\n",
    "logdir, return_dict = experiment.launch(single_ret_raw_value_params, params, local_logdir=True, name='multi ret params single comb')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting return_dict {'value': -13, 'morevals': -8, 'logfile': 'Experiments/application_1576760828949_0042_22/a=-5&b=-8/testfile.txt', 'diagram': 'img.png', 'log': 'Experiments/application_1576760828949_0042_22/a=-5&b=-8/output.log'} is a dict"
     ]
    }
   ],
   "source": [
    "logdir, return_dict = experiment.launch(multi_ret_params, params, local_logdir=True, name='multi ret params single comb', metric_key='value')\n",
    "assert_return_values(logdir, None, False, return_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Exported model 4cbdabe6-be0f-4f13-aa00-6617a3d89494 as version 1 successfully.\n",
      "Polling 4cbdabe6-be0f-4f13-aa00-6617a3d89494 version 1 for model availability.\n",
      "Model now available.\n",
      "Finished Experiment \n",
      "\n",
      "Exported model 36798f2e-5b54-40a2-821e-c59f794d4694 as version 1 successfully.\n",
      "Polling 36798f2e-5b54-40a2-821e-c59f794d4694 version 1 for model availability.\n",
      "Model now available."
     ]
    }
   ],
   "source": [
    "experiment.launch(export_model_in_wrapper, name='model exported in wrapper', local_logdir=False)\n",
    "\n",
    "experiment.launch(export_model_in_wrapper, name='model exported in wrapper', local_logdir=True)\n",
    "\n",
    "logdir, return_dict = experiment.launch(create_model_in_tensorboard_logdir, local_logdir=True, name='model exported from local logdir')\n",
    "model.export(logdir + '/model', return_dict['name'])\n",
    "\n",
    "logdir, return_dict = experiment.launch(create_model_in_tensorboard_logdir, local_logdir=False, name='model exported from hdfs logdir')\n",
    "model.export(logdir + '/model', return_dict['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_best_hyperparameters(return_dict, best_hyperparameters):\n",
    "    print('Asserting best hyperparameters in return_dict {} are {}'.format(return_dict, best_hyperparameters))\n",
    "    for key in best_hyperparameters.keys():\n",
    "        assert float(best_hyperparameters[key]) == float(return_dict[key]), '{} not equal to {}'.format(best_hyperparameters[key], return_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_return_dict(logdir, return_dict):\n",
    "    return_dict_contents = hdfs.load(logdir + '/.outputs.json')\n",
    "    logdir_return_dict = json.loads(return_dict_contents)\n",
    "    print('Assserting returned dict {} is equal to .return in best logdir {}'.format(return_dict, logdir_return_dict))\n",
    "    assert return_dict == logdir_return_dict, 'dicts are not the same {} - {}'.format(return_dict, logdir_return_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Parallel Experiments `experiment.grid_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': -5, 'b': -8} is a dict\n",
      "Asserting return_dict {'metric': -13, 'log': 'Experiments/application_1576760828949_0038_29/a=-5&b=-8/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 4.9, 'b': 10.3} is a dict\n",
      "Asserting return_dict {'metric': 15.200000000000001, 'log': 'Experiments/application_1576760828949_0038_30/a=4.9&b=10.3/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': -5, 'b': -8} is a dict\n",
      "Asserting return_dict {'value': -13, 'log': 'Experiments/application_1576760828949_0038_31/a=-5&b=-8/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 4.9, 'b': 10.3} is a dict\n",
      "Asserting return_dict {'value': 15.200000000000001, 'log': 'Experiments/application_1576760828949_0038_32/a=4.9&b=10.3/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': -5, 'b': -8} is a dict\n",
      "Asserting return_dict {'value': -13, 'morevals': -8, 'logfile': 'Experiments/application_1576760828949_0038_33/a=-5&b=-8/testfile.txt', 'diagram': 'img.png', 'log': 'Experiments/application_1576760828949_0038_33/a=-5&b=-8/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': -5, 'b': 10.3} is a dict\n",
      "Asserting return_dict {'value': -13, 'morevals': -8, 'logfile': 'Experiments/application_1576760828949_0038_33/a=-5&b=-8/testfile.txt', 'diagram': 'img.png', 'log': 'Experiments/application_1576760828949_0038_33/a=-5&b=-8/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': -1, 'b': -1.5} is a dict\n",
      "Asserting return_dict {'metric': -2.5, 'log': 'Experiments/application_1576760828949_0038_35/a=-1&b=-1.5/output.log'} is a dict\n",
      "Asserting best hyperparameters in return_dict {'a': -1, 'b': -1.5} are {'a': -1, 'b': -1.5}\n",
      "Assserting returned dict {'metric': -2.5, 'log': 'Experiments/application_1576760828949_0038_35/a=-1&b=-1.5/output.log'} is equal to .return in best logdir {'metric': -2.5, 'log': 'Experiments/application_1576760828949_0038_35/a=-1&b=-1.5/output.log'}\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 1.5, 'b': 1} is a dict\n",
      "Asserting return_dict {'metric': 2.5, 'log': 'Experiments/application_1576760828949_0038_36/a=1.5&b=1/output.log'} is a dict\n",
      "Asserting best hyperparameters in return_dict {'a': 1.5, 'b': 1} are {'a': 1.5, 'b': 1}\n",
      "Assserting returned dict {'metric': 2.5, 'log': 'Experiments/application_1576760828949_0038_36/a=1.5&b=1/output.log'} is equal to .return in best logdir {'metric': 2.5, 'log': 'Experiments/application_1576760828949_0038_36/a=1.5&b=1/output.log'}\n",
      "Finished Experiment \n",
      "\n",
      "Exported model 9c14c59a-1e0a-4169-84fd-9a829d82e7c8 as version 1 successfully.\n",
      "Polling 9c14c59a-1e0a-4169-84fd-9a829d82e7c8 version 1 for model availability.\n",
      "Model now available.\n",
      "Finished Experiment \n",
      "\n",
      "Exported model 4b3950a3-349e-4f42-94db-d116249289e6 as version 1 successfully.\n",
      "Polling 4b3950a3-349e-4f42-94db-d116249289e6 version 1 for model availability.\n",
      "Model now available."
     ]
    }
   ],
   "source": [
    "params={'a': [-5, 4.9], 'b': [-8, 10.3]}\n",
    "try:\n",
    "    experiment.grid_search(no_ret_params, params, name='fail no ret val')\n",
    "    assert False, 'should fail due to no return value'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    experiment.grid_search(multi_ret_params, params, name='fail no opt key')\n",
    "    assert False, 'should fail due to optimization_key not being set'\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_raw_value_params, params, local_logdir=True, direction=Direction.MIN)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_raw_value_params, params, local_logdir=False, direction=Direction.MAX)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_val_params, params, local_logdir=True, direction=Direction.MIN, optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_val_params, params, local_logdir=False, direction=Direction.MAX, optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(multi_ret_params, params, local_logdir=False, direction=Direction.MIN, optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, metric = experiment.grid_search(multi_ret_params, params, local_logdir=True, direction=Direction.MAX, optimization_key='morevals')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "params={'a': [-1, 1.5], 'b': [-1.5, 1]}\n",
    "\n",
    "# Make sure minimization work\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_raw_value_params, params, local_logdir=True, direction=Direction.MIN)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "assert_best_hyperparameters(hp_dict, {'a': -1, 'b': -1.5})\n",
    "assert_return_dict(logdir, return_dict)\n",
    "\n",
    "# Make sure maximization work\n",
    "logdir, hp_dict, return_dict = experiment.grid_search(single_ret_raw_value_params, params, local_logdir=True, direction=Direction.MAX)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "assert_best_hyperparameters(hp_dict, {'a': 1.5, 'b': 1})\n",
    "assert_return_dict(logdir, return_dict)\n",
    "\n",
    "best_logdir, hp_dict, return_dict = experiment.grid_search(create_model_in_tensorboard_logdir_params, params, local_logdir=True, name='grid search model exported from local logdir', optimization_key='optval', direction=Direction.MIN)\n",
    "model.export(best_logdir + '/model', return_dict['name'])\n",
    "\n",
    "best_logdir, hp_dict, return_dict = experiment.grid_search(create_model_in_tensorboard_logdir_params, params, local_logdir=False, name='grid search model exported from hdfs logdir', optimization_key='optval', direction=Direction.MAX)\n",
    "model.export(best_logdir + '/model', return_dict['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Parallel Experiments `experiment.random_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 1.2390300985714848, 'b': -6.451446027582621} is a dict\n",
      "Asserting return_dict {'metric': -5.2124159290111365, 'log': 'Experiments/application_1576760828949_0038_41/a=1.2390300985714848&b=-6.451446027582621/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': -0.032969382452864515, 'b': 8.682981990601842} is a dict\n",
      "Asserting return_dict {'metric': 8.650012608148977, 'log': 'Experiments/application_1576760828949_0038_42/a=-0.032969382452864515&b=8.682981990601842/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': -3.228158062746669, 'b': -5.604547101493724} is a dict\n",
      "Asserting return_dict {'value': -8.832705164240393, 'log': 'Experiments/application_1576760828949_0038_43/a=-3.228158062746669&b=-5.604547101493724/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': -0.7379360799420356, 'b': 8.274378875045688} is a dict\n",
      "Asserting return_dict {'value': 7.536442795103652, 'log': 'Experiments/application_1576760828949_0038_44/a=-0.7379360799420356&b=8.274378875045688/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 4.321218188104583, 'b': 5.962248963512289} is a dict\n",
      "Asserting return_dict {'value': 10.283467151616872, 'morevals': 5.962248963512289, 'logfile': 'Experiments/application_1576760828949_0038_45/a=4.321218188104583&b=5.962248963512289/testfile.txt', 'diagram': 'img.png', 'log': 'Experiments/application_1576760828949_0038_45/a=4.321218188104583&b=5.962248963512289/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': -4.756563833503053, 'b': 2.819721325563183} is a dict\n",
      "Asserting return_dict {'value': -1.9368425079398701, 'morevals': 2.819721325563183, 'logfile': 'Experiments/application_1576760828949_0038_46/a=-4.756563833503053&b=2.819721325563183/testfile.txt', 'diagram': 'img.png', 'log': 'Experiments/application_1576760828949_0038_46/a=-4.756563833503053&b=2.819721325563183/output.log'} is a dict\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': -1, 'b': -1} is a dict\n",
      "Asserting return_dict {'metric': -2, 'log': 'Experiments/application_1576760828949_0038_47/a=-1&b=-1/output.log'} is a dict\n",
      "Asserting best hyperparameters in return_dict {'a': -1, 'b': -1} are {'a': -1, 'b': -1}\n",
      "Assserting returned dict {'metric': -2, 'log': 'Experiments/application_1576760828949_0038_47/a=-1&b=-1/output.log'} is equal to .return in best logdir {'metric': -2, 'log': 'Experiments/application_1576760828949_0038_47/a=-1&b=-1/output.log'}\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 1, 'b': 1} is a dict\n",
      "Asserting return_dict {'metric': 2, 'log': 'Experiments/application_1576760828949_0038_48/a=1&b=1/output.log'} is a dict\n",
      "Asserting best hyperparameters in return_dict {'a': 1, 'b': 1} are {'a': 1, 'b': 1}\n",
      "Assserting returned dict {'metric': 2, 'log': 'Experiments/application_1576760828949_0038_48/a=1&b=1/output.log'} is equal to .return in best logdir {'metric': 2, 'log': 'Experiments/application_1576760828949_0038_48/a=1&b=1/output.log'}\n",
      "Finished Experiment \n",
      "\n",
      "Exported model ee653c8f-1a7c-4ee3-909a-094a3c71bd8c as version 1 successfully.\n",
      "Polling ee653c8f-1a7c-4ee3-909a-094a3c71bd8c version 1 for model availability.\n",
      "Model now available.\n",
      "Finished Experiment \n",
      "\n",
      "Exported model ad817459-d388-4644-a572-23a1cbbf5e64 as version 1 successfully.\n",
      "Polling ad817459-d388-4644-a572-23a1cbbf5e64 version 1 for model availability.\n",
      "Model now available."
     ]
    }
   ],
   "source": [
    "params={'a': [-5, 4.9], 'b': [-8, 10.3]}\n",
    "try:\n",
    "    experiment.random_search(no_ret_params, params, samples=2, name='fail opt no ret')\n",
    "    assert False, 'should fail due to no return value'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    experiment.random_search(multi_ret_params, params, samples=2, name='fail opt no key')\n",
    "    assert False, 'should fail due to optimization_key not being set'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(single_ret_raw_value_params, params, samples=2, local_logdir=True, direction=Direction.MIN)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(single_ret_raw_value_params, params, samples=2, local_logdir=False, direction=Direction.MAX)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(single_ret_val_params, params, samples=2, local_logdir=True, direction=Direction.MIN, optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(single_ret_val_params, params, samples=2, local_logdir=False, direction=Direction.MAX, optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(multi_ret_params, params, samples=2, local_logdir=False, direction=Direction.MAX, optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.random_search(multi_ret_params, params, samples=2, local_logdir=True, direction=Direction.MIN, optimization_key='morevals')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "params={'a': [-1, 1], 'b': [-1, 1]}\n",
    "\n",
    "# Make sure minimization work\n",
    "logdir, hp_dict, return_dict = experiment.random_search(single_ret_raw_value_params, params, local_logdir=True, direction=Direction.MIN, samples=100)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "assert_best_hyperparameters(hp_dict, {'a': -1, 'b': -1})\n",
    "assert_return_dict(logdir, return_dict)\n",
    "\n",
    "# Make sure maximization work\n",
    "logdir, hp_dict, return_dict = experiment.random_search(single_ret_raw_value_params, params, local_logdir=True, direction=Direction.MAX, samples=100)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "assert_best_hyperparameters(hp_dict, {'a': 1, 'b': 1})\n",
    "assert_return_dict(logdir, return_dict)\n",
    "\n",
    "best_logdir, hp_dict, return_dict = experiment.random_search(create_model_in_tensorboard_logdir_params, params, local_logdir=True, name='random search model exported from local logdir', optimization_key='optval', direction=Direction.MIN)\n",
    "model.export(best_logdir + '/model', return_dict['name'])\n",
    "\n",
    "best_logdir, hp_dict, return_dict = experiment.random_search(create_model_in_tensorboard_logdir_params, params, local_logdir=False, name='random search model exported from hdfs logdir', optimization_key='optval', direction=Direction.MAX)\n",
    "model.export(best_logdir + '/model', return_dict['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Parallel Experiments `experiment.differential_evolution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 || average metric: 8.166666666666666, best metric: 7.0, best parameter combination: ['a=3', 'b=4']\n",
      "\n",
      "Generation 2 || average metric: 7.166666666666667, best metric: 7.0, best parameter combination: ['a=3', 'b=4']\n",
      "\n",
      "Generation 3 || average metric: 7.0, best metric: 7.0, best parameter combination: ['a=3', 'b=4']\n",
      "\n",
      "Generation 4 || average metric: 7.0, best metric: 7.0, best parameter combination: ['a=3', 'b=4']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 2, 'b': 5} is a dict\n",
      "Asserting return_dict {'metric': 7, 'log': 'Experiments/application_1576760828949_0038_53/generation.0/a=2&b=5/output.log'} is a dict\n",
      "Generation 1 || average metric: 9.0, best metric: 11.0, best parameter combination: ['a=4', 'b=7']\n",
      "\n",
      "Generation 2 || average metric: 9.666666666666666, best metric: 11.0, best parameter combination: ['a=3', 'b=8']\n",
      "\n",
      "Generation 3 || average metric: 10.5, best metric: 12.0, best parameter combination: ['a=4', 'b=8']\n",
      "\n",
      "Generation 4 || average metric: 10.833333333333334, best metric: 12.0, best parameter combination: ['a=4', 'b=8']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 4, 'b': 8} is a dict\n",
      "Asserting return_dict {'metric': 12, 'log': 'Experiments/application_1576760828949_0038_54/generation.3/a=4&b=8/output.log'} is a dict\n",
      "Generation 1 || average metric: 9.666666666666666, best metric: 7.0, best parameter combination: ['a=2', 'b=5']\n",
      "\n",
      "Generation 2 || average metric: 8.333333333333334, best metric: 7.0, best parameter combination: ['a=2', 'b=5']\n",
      "\n",
      "Generation 3 || average metric: 7.833333333333333, best metric: 7.0, best parameter combination: ['a=1', 'b=6']\n",
      "\n",
      "Generation 4 || average metric: 7.833333333333333, best metric: 7.0, best parameter combination: ['a=1', 'b=6']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 2, 'b': 5} is a dict\n",
      "Asserting return_dict {'value': 7, 'log': 'Experiments/application_1576760828949_0038_55/generation.0/a=2&b=5/output.log'} is a dict\n",
      "Generation 1 || average metric: 10.0, best metric: 13.0, best parameter combination: ['a=3', 'b=10']\n",
      "\n",
      "Generation 2 || average metric: 11.0, best metric: 13.0, best parameter combination: ['a=3', 'b=10']\n",
      "\n",
      "Generation 3 || average metric: 11.0, best metric: 13.0, best parameter combination: ['a=3', 'b=10']\n",
      "\n",
      "Generation 4 || average metric: 11.666666666666666, best metric: 13.0, best parameter combination: ['a=3', 'b=10']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 3, 'b': 10} is a dict\n",
      "Asserting return_dict {'value': 13, 'log': 'Experiments/application_1576760828949_0038_56/generation.0/a=3&b=10/output.log'} is a dict\n",
      "Generation 1 || average metric: 9.666666666666666, best metric: 13.0, best parameter combination: ['a=3', 'b=10']\n",
      "\n",
      "Generation 2 || average metric: 11.666666666666666, best metric: 15.0, best parameter combination: ['a=5', 'b=10']\n",
      "\n",
      "Generation 3 || average metric: 11.833333333333334, best metric: 15.0, best parameter combination: ['a=5', 'b=10']\n",
      "\n",
      "Generation 4 || average metric: 13.333333333333334, best metric: 15.0, best parameter combination: ['a=5', 'b=10']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 5, 'b': 10} is a dict\n",
      "Asserting return_dict {'value': 15, 'morevals': 10, 'logfile': 'Experiments/application_1576760828949_0038_57/generation.2/a=5&b=10/testfile.txt', 'diagram': 'img.png', 'log': 'Experiments/application_1576760828949_0038_57/generation.2/a=5&b=10/output.log'} is a dict\n",
      "Generation 1 || average metric: 5.333333333333333, best metric: 3.0, best parameter combination: ['a=5', 'b=3']\n",
      "\n",
      "Generation 2 || average metric: 5.0, best metric: 3.0, best parameter combination: ['a=5', 'b=3']\n",
      "\n",
      "Generation 3 || average metric: 4.166666666666667, best metric: 3.0, best parameter combination: ['a=5', 'b=3']\n",
      "\n",
      "Generation 4 || average metric: 4.166666666666667, best metric: 3.0, best parameter combination: ['a=5', 'b=3']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 5, 'b': 3} is a dict\n",
      "Asserting return_dict {'value': 8, 'morevals': 3, 'logfile': 'Experiments/application_1576760828949_0038_58/generation.0/a=5&b=3/testfile.txt', 'diagram': 'img.png', 'log': 'Experiments/application_1576760828949_0038_58/generation.0/a=5&b=3/output.log'} is a dict\n",
      "Generation 1 || average metric: 5.333333333333333, best metric: 5.0, best parameter combination: ['a=4', 'b=1']\n",
      "\n",
      "Generation 2 || average metric: 5.166666666666667, best metric: 5.0, best parameter combination: ['a=4', 'b=1']\n",
      "\n",
      "Generation 3 || average metric: 5.166666666666667, best metric: 5.0, best parameter combination: ['a=4', 'b=1']\n",
      "\n",
      "Generation 4 || average metric: 5.0, best metric: 5.0, best parameter combination: ['a=4', 'b=1']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 4, 'b': 1} is a dict\n",
      "Asserting return_dict {'metric': 5, 'log': 'Experiments/application_1576760828949_0038_59/generation.0/a=4&b=1/output.log'} is a dict\n",
      "Asserting best hyperparameters in return_dict {'a': 4, 'b': 1} are {'a': 4, 'b': 1}\n",
      "Assserting returned dict {'metric': 5, 'log': 'Experiments/application_1576760828949_0038_59/generation.0/a=4&b=1/output.log'} is equal to .return in best logdir {'metric': 5, 'log': 'Experiments/application_1576760828949_0038_59/generation.0/a=4&b=1/output.log'}\n",
      "Generation 1 || average metric: 6.666666666666667, best metric: 7.0, best parameter combination: ['a=5', 'b=2']\n",
      "\n",
      "Generation 2 || average metric: 7.0, best metric: 7.0, best parameter combination: ['a=5', 'b=2']\n",
      "\n",
      "Generation 3 || average metric: 7.0, best metric: 7.0, best parameter combination: ['a=5', 'b=2']\n",
      "\n",
      "Generation 4 || average metric: 7.0, best metric: 7.0, best parameter combination: ['a=5', 'b=2']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Asserting hp_dict {'a': 5, 'b': 2} is a dict\n",
      "Asserting return_dict {'metric': 7, 'log': 'Experiments/application_1576760828949_0038_60/generation.0/a=5&b=2/output.log'} is a dict\n",
      "Asserting best hyperparameters in return_dict {'a': 5, 'b': 2} are {'a': 5, 'b': 2}\n",
      "Assserting returned dict {'metric': 7, 'log': 'Experiments/application_1576760828949_0038_60/generation.0/a=5&b=2/output.log'} is equal to .return in best logdir {'metric': 7, 'log': 'Experiments/application_1576760828949_0038_60/generation.0/a=5&b=2/output.log'}\n",
      "Generation 1 || average metric: 6.333333333333333, best metric: 6.0, best parameter combination: ['a=4', 'b=2']\n",
      "\n",
      "Generation 2 || average metric: 6.0, best metric: 6.0, best parameter combination: ['a=4', 'b=2']\n",
      "\n",
      "Generation 3 || average metric: 6.0, best metric: 6.0, best parameter combination: ['a=4', 'b=2']\n",
      "\n",
      "Generation 4 || average metric: 6.0, best metric: 6.0, best parameter combination: ['a=4', 'b=2']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Exported model e5947fc4-9e19-4bfa-bd79-5a33fd685492 as version 1 successfully.\n",
      "Polling e5947fc4-9e19-4bfa-bd79-5a33fd685492 version 1 for model availability.\n",
      "Model now available.\n",
      "Generation 1 || average metric: 6.166666666666667, best metric: 7.0, best parameter combination: ['a=5', 'b=2']\n",
      "\n",
      "Generation 2 || average metric: 6.5, best metric: 7.0, best parameter combination: ['a=5', 'b=2']\n",
      "\n",
      "Generation 3 || average metric: 6.666666666666667, best metric: 7.0, best parameter combination: ['a=5', 'b=2']\n",
      "\n",
      "Generation 4 || average metric: 6.666666666666667, best metric: 7.0, best parameter combination: ['a=5', 'b=2']\n",
      "\n",
      "Finished Experiment \n",
      "\n",
      "Exported model db9ad5d4-e4a2-4fa5-8166-b48fb84176b9 as version 1 successfully.\n",
      "Polling db9ad5d4-e4a2-4fa5-8166-b48fb84176b9 version 1 for model availability.\n",
      "Model now available."
     ]
    }
   ],
   "source": [
    "params={'a': [1, 4.9], 'b': [3, 10.3]}\n",
    "try:\n",
    "    experiment.differential_evolution(no_ret_params, params, name='fail opt no ret')\n",
    "    assert False, 'should fail due to no return value'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    experiment.differential_evolution(multi_ret_params, params, name='fail opt no key')\n",
    "    assert False, 'should fail due to optimization_key not being set'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(single_ret_raw_value_params, params, local_logdir=True, direction=Direction.MIN)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(single_ret_raw_value_params, params, local_logdir=False, direction=Direction.MAX)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(single_ret_val_params, params, local_logdir=True, direction=Direction.MIN, optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(single_ret_val_params, params,local_logdir=False, direction=Direction.MAX, optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(multi_ret_params, params, local_logdir=False, direction=Direction.MAX, optimization_key='value')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(multi_ret_params, params, local_logdir=True, direction=Direction.MIN, optimization_key='morevals')\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "\n",
    "params={'a': [4, 5], 'b': [1, 2]}\n",
    "\n",
    "# Make sure minimization work\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(single_ret_raw_value_params, params, local_logdir=True, direction=Direction.MIN)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "assert_best_hyperparameters(hp_dict, {'a': 4, 'b': 1})\n",
    "assert_return_dict(logdir, return_dict)\n",
    "\n",
    "# Make sure maximization work\n",
    "logdir, hp_dict, return_dict = experiment.differential_evolution(single_ret_raw_value_params, params, local_logdir=True, direction=Direction.MAX)\n",
    "assert_return_values(logdir, hp_dict, True, return_dict, True)\n",
    "assert_best_hyperparameters(hp_dict, {'a': 5, 'b': 2})\n",
    "assert_return_dict(logdir, return_dict)\n",
    "\n",
    "best_logdir, hp_dict, return_dict = experiment.differential_evolution(create_model_in_tensorboard_logdir_params, params, local_logdir=True, name='diff evo model exported from local logdir', optimization_key='optval', direction=Direction.MIN)\n",
    "model.export(best_logdir + '/model', return_dict['name'])\n",
    "\n",
    "best_logdir, hp_dict, return_dict = experiment.differential_evolution(create_model_in_tensorboard_logdir_params, params, local_logdir=False, name='diff evo model exported from hdfs logdir', optimization_key='optval', direction=Direction.MAX)\n",
    "model.export(best_logdir + '/model', return_dict['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_exp_asserts():\n",
    "    from hops import tensorboard\n",
    "    from hops import devices\n",
    "    from hops import hdfs\n",
    "    import os\n",
    "    assert devices.get_num_gpus()==0\n",
    "    assert hdfs.project_path() == hdfs.project_path(hdfs.project_name())\n",
    "    \n",
    "    tf_config = json.loads(os.environ['TF_CONFIG'])\n",
    "    \n",
    "    role = tf_config['task']['type']\n",
    "    \n",
    "    print(tensorboard.logdir())\n",
    "    \n",
    "    # Only chief and evaluator role should have access to TB logdir to write checkpoints/summary/evaluation etc\n",
    "    if role == 'chief':\n",
    "        assert tensorboard.logdir() != None, 'chief TB is None'\n",
    "        if tensorboard.local_logdir_bool:\n",
    "            assert \"hdfs://\" not in tensorboard.logdir(), 'chief TB is not local'\n",
    "            assert os.path.exists(tensorboard.logdir()), 'chief local TB path does not exists'\n",
    "        else:\n",
    "            assert \"hdfs://\" in tensorboard.logdir(), 'chief TB is not in HDFS'\n",
    "            assert hdfs.exists(tensorboard.logdir()), 'chief hdfs TB path does not exists'\n",
    "    elif role == 'worker' or role == 'ps':\n",
    "        assert tensorboard.logdir() == None, 'ps or worker TB is not None {}'.format(tf_config)\n",
    "    elif role == 'evaluator':\n",
    "        assert tensorboard.logdir() != None, 'evaluator TB is None'\n",
    "        assert hdfs.exists(tensorboard.logdir()), 'evaluator TB path does not exists'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_ret():\n",
    "    dist_exp_asserts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_return():\n",
    "    dist_exp_asserts()\n",
    "    f = open('testfile.txt', 'w')\n",
    "    f.write('stuff happened')\n",
    "    f.close()\n",
    "    f = open('img.png', 'w')\n",
    "    f.write('stuff happened')\n",
    "    f.close()\n",
    "    return {'value': 10, 'morevals': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "('hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Experiments/application_1576760828949_0042_33', {'log': 'Experiments/application_1576760828949_0042_33/chief_0_output.log'})"
     ]
    }
   ],
   "source": [
    "experiment.mirrored(no_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "('hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Experiments/application_1576760828949_0042_34', {'value': 10, 'morevals': 3, 'log': 'Experiments/application_1576760828949_0042_34/output.log'})"
     ]
    }
   ],
   "source": [
    "experiment.mirrored(multi_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 34.0 failed 1 times, most recent failure: Lost task 1.0 in stage 34.0 (TID 61, hopsworks0.logicalclocks.com, executor 4): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$3.applyOrElse(PythonRunner.scala:486)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$3.applyOrElse(PythonRunner.scala:475)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:593)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n",
      "\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.EOFException\n",
      "\tat java.io.DataInputStream.readInt(DataInputStream.java:392)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:578)\n",
      "\t... 26 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:166)\n",
      "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
      "\tat sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$3.applyOrElse(PythonRunner.scala:486)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$3.applyOrElse(PythonRunner.scala:475)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:593)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n",
      "\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: java.io.EOFException\n",
      "\tat java.io.DataInputStream.readInt(DataInputStream.java:392)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:578)\n",
      "\t... 26 more\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/experiment.py\", line 591, in mirrored\n",
      "    logdir = mirrored_impl._run(sc, map_fun, run_id, local_logdir=local_logdir, name=name, evaluator=evaluator)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/experiment_impl/distribute/mirrored.py\", line 47, in _run\n",
      "    nodeRDD.foreachPartition(_prepare_func(app_id, run_id, map_fun, local_logdir, server_addr, evaluator, util.num_executors()))\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 806, in foreachPartition\n",
      "    self.mapPartitions(func).count()  # Force evaluation\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1055, in count\n",
      "    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1046, in sum\n",
      "    return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add)\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 917, in fold\n",
      "    vals = self.mapPartitions(func).collect()\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 816, in collect\n",
      "    sock_info = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())\n",
      "  File \"/srv/hops/spark/python/lib/py4j-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/srv/hops/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/srv/hops/spark/python/lib/py4j-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 34.0 failed 1 times, most recent failure: Lost task 1.0 in stage 34.0 (TID 61, hopsworks0.logicalclocks.com, executor 4): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$3.applyOrElse(PythonRunner.scala:486)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$3.applyOrElse(PythonRunner.scala:475)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:593)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n",
      "\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: java.io.EOFException\n",
      "\tat java.io.DataInputStream.readInt(DataInputStream.java:392)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:578)\n",
      "\t... 26 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:166)\n",
      "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
      "\tat sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$3.applyOrElse(PythonRunner.scala:486)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$3.applyOrElse(PythonRunner.scala:475)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:593)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n",
      "\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: java.io.EOFException\n",
      "\tat java.io.DataInputStream.readInt(DataInputStream.java:392)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:578)\n",
      "\t... 26 more\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.mirrored(export_model_in_wrapper, name='mirrored model exported in wrapper', local_logdir=False)\n",
    "\n",
    "experiment.mirrored(export_model_in_wrapper, name='mirrored model exported in wrapper', local_logdir=True)\n",
    "\n",
    "logdir, return_dict = experiment.mirrored(create_model_in_tensorboard_logdir, local_logdir=True, name='mirrored model exported from local logdir')\n",
    "model.export(logdir + '/model', return_dict['name'])\n",
    "\n",
    "logdir, return_dict = experiment.mirrored(create_model_in_tensorboard_logdir, local_logdir=False, name='mirrored model exported from hdfs logdir')\n",
    "model.export(logdir + '/model', return_dict['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HopsFS Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test HopsFS operations\n",
    "\n",
    "- `hdfs.project_user()`\n",
    "- `hdfs.project_name()`\n",
    "- `hdfs.project_path()`\n",
    "- `hdfs.exists()`\n",
    "- `hdfs.load()`\n",
    "- `hdfs.copy_to_hdfs()`\n",
    "- `hdfs.copy_to_local()`\n",
    "- `hdfs.ls()`\n",
    "- `hdfs.lsl()`\n",
    "- `hdfs.glob()`\n",
    "- `hdfs.cp()`\n",
    "- `hdfs.rmr()`\n",
    "- `hdfs.rename()`\n",
    "- `hdfs.stat()`\n",
    "- `hdfs.isdir()`\n",
    "- `hdfs.isfile()`\n",
    "- `hdfs.add_module()`\n",
    "- `hdfs.delete()`\n",
    "- `hdfs.get_plain_path()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_user = hdfs.project_user()\n",
    "project_name = hdfs.project_name()\n",
    "assert project_name in project_user\n",
    "project_path = hdfs.project_path()\n",
    "assert project_name in project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_README = hdfs.load(\"Logs/README.md\")\n",
    "assert len(logs_README) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.dump(\"test\", \"Logs/README_dump_test.md\")\n",
    "assert hdfs.exists(\"Logs/README_dump_test.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_README_dumped = hdfs.load(\"Logs/README_dump_test.md\")\n",
    "assert logs_README_dumped.decode(\"utf-8\") == \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying local path upload.txt to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path upload.txt to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/upload.txt\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path upload.txt to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources"
     ]
    }
   ],
   "source": [
    "# copy_to_hdfs file relative path\n",
    "\n",
    "with open('upload.txt', 'w') as f:\n",
    "    f.write(\"first upload\")\n",
    "hdfs.copy_to_hdfs(\"upload.txt\", \"Resources\")\n",
    "assert hdfs.exists(\"Resources/upload.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload.txt\")\n",
    "assert \"first upload\" == hdfs_copied_file.decode(\"utf-8\"), \"first content does not match\"\n",
    "\n",
    "with open('upload.txt', 'w') as f:\n",
    "    f.write(\"second upload\")\n",
    "hdfs.copy_to_hdfs(\"upload.txt\", \"Resources\", overwrite=True)\n",
    "assert hdfs.exists(\"Resources/upload.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload.txt\")\n",
    "assert \"second upload\" == hdfs_copied_file.decode(\"utf-8\"), \"second content does not match\"\n",
    "\n",
    "try:\n",
    "    hdfs.copy_to_hdfs(\"upload.txt\", \"Resources\")\n",
    "    assert False\n",
    "except IOError:\n",
    "    pass\n",
    "\n",
    "hdfs.rmr(\"Resources/upload.txt\")\n",
    "os.remove(\"upload.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying local path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/upload_absolute.txt to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/upload_absolute.txt to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/upload_absolute.txt\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path upload_absolute.txt to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources"
     ]
    }
   ],
   "source": [
    "# copy_to_hdfs file absolute path\n",
    "\n",
    "with open('upload_absolute.txt', 'w') as f:\n",
    "    f.write(\"first upload\")\n",
    "hdfs.copy_to_hdfs(os.getcwd() + \"/upload_absolute.txt\", \"Resources\")\n",
    "assert hdfs.exists(\"Resources/upload_absolute.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_absolute.txt\")\n",
    "assert \"first upload\" == hdfs_copied_file.decode(\"utf-8\"), \"first content does not match\"\n",
    "\n",
    "with open('upload_absolute.txt', 'w') as f:\n",
    "    f.write(\"second upload\")\n",
    "hdfs.copy_to_hdfs(os.getcwd() + \"/upload_absolute.txt\", \"Resources\", overwrite=True)\n",
    "assert hdfs.exists(\"Resources/upload_absolute.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_absolute.txt\")\n",
    "assert \"second upload\" == hdfs_copied_file.decode(\"utf-8\"), \"second content does not match\"\n",
    "\n",
    "try:\n",
    "    hdfs.copy_to_hdfs(\"upload_absolute.txt\", \"Resources\")\n",
    "    assert False\n",
    "except IOError:\n",
    "    pass\n",
    "\n",
    "hdfs.rmr(\"Resources/upload_absolute.txt\")\n",
    "os.remove(\"upload_absolute.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying local path upload_dir to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path upload_dir to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/upload_dir\n",
      "\n",
      "Finished copying"
     ]
    }
   ],
   "source": [
    "# copy_to_hdfs directory relative path\n",
    "\n",
    "if not os.path.exists(\"upload_dir\"):\n",
    "    os.mkdir(\"upload_dir\")\n",
    "\n",
    "assert not hdfs.exists(\"Resources/upload_dir\")\n",
    "with open('upload_dir/upload.txt', 'w') as f:\n",
    "    f.write(\"first upload\")\n",
    "hdfs.copy_to_hdfs(\"upload_dir\", \"Resources\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_dir/upload.txt\")\n",
    "assert hdfs.exists(\"Resources/upload_dir\")\n",
    "with open('upload_dir/upload.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"first content compare failed\"\n",
    "\n",
    "with open('upload_dir/upload.txt', 'w') as f:\n",
    "    f.write(\"second upload\")\n",
    "hdfs.copy_to_hdfs(\"upload_dir\", \"Resources\", overwrite=True)\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_dir/upload.txt\")\n",
    "assert hdfs.exists(\"Resources/upload_dir\")\n",
    "with open('upload_dir/upload.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"second content compare failed\"\n",
    "\n",
    "shutil.rmtree(\"upload_dir\")\n",
    "hdfs.rmr(\"Resources/upload_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying local path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/upload_dir_absolute to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/upload_dir_absolute to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/upload_dir_absolute\n",
      "\n",
      "Finished copying"
     ]
    }
   ],
   "source": [
    "# copy_to_hdfs directory absolute path\n",
    "\n",
    "if not os.path.exists(\"upload_dir_absolute\"):\n",
    "    os.mkdir(\"upload_dir_absolute\")\n",
    "    \n",
    "assert not hdfs.exists(\"Resources/upload_dir_absolute\")\n",
    "with open('upload_dir_absolute/upload.txt', 'w') as f:\n",
    "    f.write(\"first upload\")\n",
    "hdfs.copy_to_hdfs(os.getcwd() + \"/upload_dir_absolute\", \"Resources\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_dir_absolute/upload.txt\")\n",
    "assert hdfs.exists(\"Resources/upload_dir_absolute\")\n",
    "with open('upload_dir_absolute/upload.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"first content compare failed\"\n",
    "\n",
    "with open('upload_dir_absolute/upload.txt', 'w') as f:\n",
    "    f.write(\"second upload\")\n",
    "hdfs.copy_to_hdfs(os.getcwd() + \"/upload_dir_absolute\", \"Resources\", overwrite=True)\n",
    "hdfs_copied_file = hdfs.load(\"Resources/upload_dir_absolute/upload.txt\")\n",
    "assert hdfs.exists(\"Resources/upload_dir_absolute\")\n",
    "with open('upload_dir_absolute/upload.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"second content compare failed\"\n",
    "\n",
    "shutil.rmtree(\"upload_dir_absolute\")\n",
    "hdfs.rmr(\"Resources/upload_dir_absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/somefile.txt to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/\n",
      "\n",
      "Finished copying\n",
      "\n",
      "File hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/somefile.txt is already localized, skipping download...\n",
      "Started copying hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/somefile.txt to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/somefile.txt to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/\n",
      "\n",
      "Finished copying\n",
      "\n",
      "File hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/somefile.txt is already localized, skipping download..."
     ]
    }
   ],
   "source": [
    "#copy_to_local file\n",
    "\n",
    "# Download first time\n",
    "hdfs.dump(\"initial content\", \"Resources/somefile.txt\")\n",
    "hdfs.copy_to_local(\"Resources/somefile.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/somefile.txt\")\n",
    "with open('somefile.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"first content compare failed\"\n",
    "first_modified = os.path.getmtime(\"somefile.txt\")\n",
    "\n",
    "# Download second time\n",
    "hdfs.copy_to_local(\"Resources/somefile.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/somefile.txt\")\n",
    "with open('somefile.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"second content compare failed\"\n",
    "second_modified = os.path.getmtime(\"somefile.txt\")\n",
    "assert first_modified == second_modified, \"modified time not matching\"\n",
    "\n",
    "# Content changing on disk\n",
    "hdfs.dump(\"content changed at some point\", \"Resources/somefile.txt\")\n",
    "hdfs_new_content = hdfs.load(\"Resources/somefile.txt\")\n",
    "hdfs.copy_to_local(\"Resources/somefile.txt\")\n",
    "with open('somefile.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_new_content.decode(\"utf-8\") == local_copied_file, \"third content compare failed\"\n",
    "third_modified = os.path.getmtime(\"somefile.txt\")\n",
    "assert not second_modified == third_modified, \"modified time not matching\"\n",
    "\n",
    "# Download last time with overwrite, file should have changed on disk\n",
    "hdfs.copy_to_local(\"Resources/somefile.txt\", overwrite=True)\n",
    "hdfs_copied_file = hdfs.load(\"Resources/somefile.txt\")\n",
    "with open('somefile.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"fourth content compare failed\"\n",
    "fourth_modified = os.path.getmtime(\"somefile.txt\")\n",
    "assert not third_modified == fourth_modified, \"modified time not matching\"\n",
    "\n",
    "# Download again to make sure overwrite did not cause problems\n",
    "hdfs.copy_to_local(\"Resources/somefile.txt\")\n",
    "hdfs_copied_file = hdfs.load(\"Resources/somefile.txt\")\n",
    "with open('somefile.txt', 'r') as f:\n",
    "    local_copied_file = f.read()\n",
    "assert hdfs_copied_file.decode(\"utf-8\") == local_copied_file, \"fifth content compare failed\"\n",
    "fifth_modified = os.path.getmtime(\"somefile.txt\")\n",
    "assert fourth_modified == fifth_modified, \"modified time not matching\"\n",
    "\n",
    "hdfs.rmr(\"Resources/somefile.txt\")\n",
    "os.remove(\"somefile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Full directory subtree already on local disk and unchanged. Set overwrite=True to force download\n",
      "Started copying hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/\n",
      "\n",
      "Finished copying"
     ]
    }
   ],
   "source": [
    "#copy_to_local directory\n",
    "\n",
    "assert not os.path.exists(\"Resources\")\n",
    "hdfs.copy_to_local(\"Resources\")\n",
    "first_modified = os.path.getmtime(\"Resources\")\n",
    "assert os.path.exists(\"Resources\")\n",
    "assert os.path.isdir(\"Resources\")\n",
    "\n",
    "hdfs.copy_to_local(\"Resources\")\n",
    "second_modified = os.path.getmtime(\"Resources\")\n",
    "assert first_modified == second_modified\n",
    "\n",
    "localized_dir = hdfs.copy_to_local(\"Resources\", overwrite=True)\n",
    "third_modified = os.path.getmtime(\"Resources\")\n",
    "assert not second_modified == third_modified\n",
    "num_files_first = len(os.listdir(localized_dir))\n",
    "\n",
    "# Add a new file, it should also be localized\n",
    "hdfs.dump(\"a wild file appeared\", \"Resources/newfile.txt\")\n",
    "hdfs.copy_to_local(\"Resources\")\n",
    "fourth_modified = os.path.getmtime(\"Resources\")\n",
    "assert first_modified == second_modified\n",
    "num_files_second = len(os.listdir(localized_dir))\n",
    "assert (num_files_first + 1) == num_files_second\n",
    "assert not third_modified == fourth_modified\n",
    "\n",
    "hdfs.rmr(\"Resources/newfile.txt\")\n",
    "shutil.rmtree(\"Resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_md = hdfs.glob(\"Logs/*.md\")\n",
    "logs_path_names = hdfs.lsl(\"Logs/\")\n",
    "if hdfs.exists(\"Logs/test.txt\"):\n",
    "    hdfs.rmr(\"Logs/test.txt\")\n",
    "assert not hdfs.exists(\"Logs/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.dump(\"dummy\", \"Resources/test.txt\")\n",
    "hdfs.cp(\"Resources/test.txt\", \"Logs/\")\n",
    "logs_files = hdfs.ls(\"Logs/\")\n",
    "assert \"test.txt\" in \",\".join(logs_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.mkdir(\"Logs/test_dir\")\n",
    "assert hdfs.exists(\"Logs/test_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_prior_delete = hdfs.ls(\"Logs/\")\n",
    "hdfs.rmr(\"Logs/test_dir\")\n",
    "logs_files_after_delete = hdfs.ls(\"Logs/\")\n",
    "assert len(logs_files_prior_delete) > len(logs_files_after_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_prior_move = hdfs.ls(\"Logs/\")\n",
    "assert \"README_dump_test.md\" in \",\".join(logs_files_prior_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.move(\"Logs/README_dump_test.md\", \"Logs/README_dump_test2.md\")\n",
    "logs_files_after_move = hdfs.ls(\"Logs/\")\n",
    "assert \"README_dump_test.md\" not in \",\".join(logs_files_after_move)\n",
    "assert \"README_dump_test2.md\" in \",\".join(logs_files_after_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_files_prior_rename = hdfs.ls(\"Logs/\")\n",
    "assert \"README_dump_test2.md\" in \",\".join(logs_files_prior_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.rename(\"Logs/README_dump_test2.md\", \"Logs/README_dump_test.md\")\n",
    "logs_files_after_rename = hdfs.ls(\"Logs/\")\n",
    "assert \"Logs/README_dump_test2.md\" not in \",\".join(logs_files_after_rename)\n",
    "assert \"Logs/README_dump_test.md\" in \",\".join(logs_files_after_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stat = hdfs.stat(\"Logs/README.md\")\n",
    "hdfs.chmod(\"Logs/README.md\", 775)\n",
    "file_stat = hdfs.stat(\"Logs/README.md\")\n",
    "assert 775 == file_stat.st_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.chmod(\"Logs/README.md\", 777)\n",
    "file_stat = hdfs.stat(\"Logs/README.md\")\n",
    "assert 777 == file_stat.st_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_owner = file_stat.st_uid\n",
    "assert hdfs.exists(\"Logs/\")\n",
    "assert not hdfs.exists(\"Not_Existing/neither_am_i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hdfs.isdir(\"Resources\")\n",
    "assert not hdfs.isdir(\"Resources/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hdfs.isfile(\"Resources/README.md\")\n",
    "assert not hdfs.isfile(\"Resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/my_module.py to local disk on path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/localized_deps\n",
      "\n",
      "Finished copying"
     ]
    }
   ],
   "source": [
    "hdfs.dump(\"def simple():\\n\\treturn 5\", \"Resources/my_module.py\")\n",
    "py_path = hdfs.add_module(\"Resources/my_module.py\")\n",
    "assert py_path in sys.path\n",
    "import my_module\n",
    "assert my_module.simple() == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain = hdfs.get_plain_path(\"hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Models/\")\n",
    "assert plain == \"/Projects/demo_deep_learning_admin000/Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.mkdir(\"Logs/test_delete_dir\")\n",
    "assert hdfs.exists(\"Logs/test_delete_dir\")\n",
    "hdfs.delete(\"Logs/test_delete_dir\")\n",
    "assert not hdfs.exists(\"Logs/test_delete_dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Store Tests\n",
    "\n",
    "These tests require that you have the following files in the Resources directory:\n",
    "\n",
    "- `attendances_features.csv`\n",
    "- `games_features.csv`\n",
    "- `players_features.csv`\n",
    "- `season_scores_features.csv`\n",
    "- `teams_features.csv`\n",
    "\n",
    "These files can be downloaded from here: `http://snurran.sics.se/hops/hops-util-py_test/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Featurestore Create Feature Group Operations (`featurestore.create_featuregroup()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fs_sample_data():\n",
    "    resources_path = hdfs.project_path() + \"Resources/\"\n",
    "    games_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"games_features.csv\")\n",
    "    players_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"players_features.csv\")\n",
    "    teams_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"teams_features.csv\")\n",
    "    season_scores_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\",\"true\").load(resources_path + \"season_scores_features.csv\")\n",
    "    attendances_features_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(resources_path + \"attendances_features.csv\")\n",
    "    return games_features_df,players_features_df,teams_features_df,season_scores_features_df, attendances_features_df\n",
    "games_features_df,players_features_df,teams_features_df,season_scores_features_df, attendances_features_df = load_fs_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : games_features, version: 1\n",
      "computing feature correlation for: games_features, version: 1\n",
      "computing feature histograms for: games_features, version: 1\n",
      "computing cluster analysis for: games_features, version: 1\n",
      "Registering feature metadata...\n",
      "Registering feature metadata... [COMPLETE]\n",
      "Writing feature data to offline feature group (Hive)...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Writing feature data to offline feature group (Hive)... [COMPLETE]\n",
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    games_features_df,\n",
    "    \"games_features\",\n",
    "    description=\"Features of average season scores for football teams\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : teams_features, version: 1\n",
      "computing feature correlation for: teams_features, version: 1\n",
      "computing feature histograms for: teams_features, version: 1\n",
      "computing cluster analysis for: teams_features, version: 1\n",
      "Registering feature metadata...\n",
      "Registering feature metadata... [COMPLETE]\n",
      "Writing feature data to offline feature group (Hive)...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Writing feature data to offline feature group (Hive)... [COMPLETE]\n",
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_df,\n",
    "    \"teams_features\",\n",
    "    description=\"a spanish version of teams_features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : season_scores_features, version: 1\n",
      "computing feature correlation for: season_scores_features, version: 1\n",
      "computing feature histograms for: season_scores_features, version: 1\n",
      "computing cluster analysis for: season_scores_features, version: 1\n",
      "Registering feature metadata...\n",
      "Registering feature metadata... [COMPLETE]\n",
      "Writing feature data to offline feature group (Hive)...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Writing feature data to offline feature group (Hive)... [COMPLETE]\n",
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    season_scores_features_df,\n",
    "    \"season_scores_features\",\n",
    "    description=\"Features of average season scores for football teams\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : attendances_features, version: 1\n",
      "computing feature correlation for: attendances_features, version: 1\n",
      "computing feature histograms for: attendances_features, version: 1\n",
      "computing cluster analysis for: attendances_features, version: 1\n",
      "Registering feature metadata...\n",
      "Registering feature metadata... [COMPLETE]\n",
      "Writing feature data to offline feature group (Hive)...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Writing feature data to offline feature group (Hive)... [COMPLETE]\n",
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    attendances_features_df,\n",
    "    \"attendances_features\",\n",
    "    description=\"Features of average attendance of games of football teams\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM teams_features_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "teams_features_1_df = featurestore.get_featuregroup(\"teams_features\")\n",
    "teams_features_2_df = teams_features_1_df.withColumnRenamed(\n",
    "    \"team_id\", \"equipo_id\").withColumnRenamed(\n",
    "    \"team_budget\", \"equipo_presupuesto\").withColumnRenamed(\n",
    "    \"team_position\", \"equipo_posicion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering feature metadata...\n",
      "Registering feature metadata... [COMPLETE]\n",
      "Writing feature data to offline feature group (Hive)...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Writing feature data to offline feature group (Hive)... [COMPLETE]\n",
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_2_df,\n",
    "    \"teams_features_spanish\",\n",
    "    description=\"a spanish version of teams_features\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not create feature group (url: /hopsworks-api/api/project/183/featurestores/131/featuregroups), server response: \n",
      " HTTP code: 400, HTTP reason: Bad Request, error code: 270089, error msg: The feature group you are trying to create does already exist., user msg: project: ittests, featurestoreId: 131\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/hops/featurestore.py\", line 648, in create_featuregroup\n",
      "    online=online, online_types=online_types, offline=offline)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/hops/featurestore_impl/core.py\", line 1841, in _do_create_featuregroup\n",
      "    None, None, online)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/hops/featurestore_impl/rest/rest_rpc.py\", line 291, in _create_featuregroup_rest\n",
      "    resource_url, response.status_code, response.reason, error_code, error_msg, user_msg))\n",
      "hops.exceptions.RestAPIError: Could not create feature group (url: /hopsworks-api/api/project/183/featurestores/131/featuregroups), server response: \n",
      " HTTP code: 400, HTTP reason: Bad Request, error code: 270089, error msg: The feature group you are trying to create does already exist., user msg: project: ittests, featurestoreId: 131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_2_df,\n",
    "    \"teams_features_spanish\",\n",
    "    description=\"a spanish version of teams_features\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    featuregroup_version=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering feature metadata...\n",
      "Registering feature metadata... [COMPLETE]\n",
      "Writing feature data to offline feature group (Hive)...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Writing feature data to offline feature group (Hive)... [COMPLETE]\n",
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    teams_features_2_df,\n",
    "    \"teams_features_spanish\",\n",
    "    description=\"a spanish version of teams_features\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    featuregroup_version=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "from hops import hdfs\n",
    "query = \"SELECT * FROM games_features_1 WHERE score > 1\"\n",
    "storage_connector = hdfs.project_name() + \"_featurestore\"\n",
    "featuregroup_name = \"games_features_on_demand\"\n",
    "featurestore.create_on_demand_featuregroup(query, featuregroup_name, storage_connector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"games_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"teams_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"season_scores_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"attendances_features_1\" in featurestore.get_featuregroups()\n",
    "assert \"teams_features_spanish_1\" in featurestore.get_featuregroups()\n",
    "assert \"teams_features_spanish_2\" in featurestore.get_featuregroups()\n",
    "assert \"games_features_on_demand_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Featurestore Utility Operations, \n",
    "\n",
    "- `featurestore.get_metadata()`,\n",
    "- `featurestore.project_featurestore()`, \n",
    "- `featurestore.get_latest_featuregroup_version()`, \n",
    "- `featurestore.get_features_list()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hops.featurestore_impl.dao.common.featurestore_metadata.FeaturestoreMetadata object at 0x7f80d5eeb908>"
     ]
    }
   ],
   "source": [
    "featurestore.get_featurestore_metadata(update_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert featurestore.project_featurestore() == hdfs.project_name() + \"_featurestore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert featurestore.project_featurestore() in featurestore.get_project_featurestores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(featurestore.get_project_featurestores()) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert featurestore.get_latest_featuregroup_version(\"teams_features_spanish\") == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert featurestore.get_latest_featuregroup_version(\"teams_features\") == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"away_team_id\" in featurestore.get_features_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"home_team_id\" in featurestore.get_features_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (hdfs.project_name() + \"_featurestore\", 'JDBC') in featurestore.get_storage_connectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(featurestore.get_storage_connectors()) >= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Read operations of Features and Feature Groups, \n",
    "\n",
    "- `featurestore.get_feature()`, \n",
    "- `featurestore.get_features()`, \n",
    "- `featurestore.get_featuregroup()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 1 feature from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget FROM teams_features_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_feature(\"team_budget\")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 1\n",
    "assert \"team_budget\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 1 feature from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget FROM teams_features_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_feature(\n",
    "    \"team_budget\", \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    featuregroup=\"teams_features\", \n",
    "    featuregroup_version = 1,\n",
    "    dataframe_type = \"spark\"\n",
    ")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 1\n",
    "assert \"team_budget\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM teams_features_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_featuregroup(\"teams_features\")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM teams_features_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_featuregroup(\n",
    "    \"teams_features\", \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    featuregroup_version = 1,\n",
    "    dataframe_type = \"spark\"\n",
    ")\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 2 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id` against offline feature store"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"average_attendance\"]\n",
    "tmp = featurestore.get_features(\n",
    "    features\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 2 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT attendances_features_1.average_attendance, teams_features_1.team_budget FROM attendances_features_1 JOIN teams_features_1 ON attendances_features_1.`team_id`=teams_features_1.`team_id` against offline feature store"
     ]
    }
   ],
   "source": [
    "features = [\"teams_features_1.team_budget\", \"attendances_features_1.average_attendance\"]\n",
    "tmp = featurestore.get_features(features)\n",
    "assert set([\"team_budget\", \"average_attendance\"]) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 2 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget, average_attendance FROM attendances_features_1 JOIN teams_features_1 ON attendances_features_1.`team_id`=teams_features_1.`team_id` against offline feature store"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"average_attendance\"]\n",
    "tmp = featurestore.get_features(\n",
    "    features,\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    featuregroups_version_dict={\n",
    "        \"teams_features\": 1, \n",
    "        \"attendances_features\": 1\n",
    "    }\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 2 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id` against offline feature store"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.get_features(\n",
    "    features,\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    featuregroups_version_dict={\n",
    "        \"teams_features\": 1, \n",
    "        \"attendances_features\": 1\n",
    "    },\n",
    "    join_key = \"team_id\",\n",
    "    dataframe_type = \"spark\"\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 4 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT sum_attendance, team_budget, average_attendance, team_position FROM attendances_features_1 JOIN teams_features_1 ON attendances_features_1.`team_id`=teams_features_1.`team_id` against offline feature store"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"average_attendance\",\n",
    "    \"team_position\", \"sum_attendance\"\n",
    "    ]\n",
    "tmp = featurestore.get_features(\n",
    "   features\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 2 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget, team_id FROM teams_features_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "features = [\"team_budget\", \"team_id\"]\n",
    "tmp = featurestore.get_features(\n",
    "    features,\n",
    "    featuregroups_version_dict = {\n",
    "        \"teams_features\" : 1\n",
    "    }\n",
    ")\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 50\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Running sql: SELECT team_budget, score FROM teams_features_1 JOIN games_features_1 ON games_features_1.home_team_id = teams_features_1.team_id against offline feature store"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.sql(\n",
    "    \"SELECT team_budget, score \" \\\n",
    "    \"FROM teams_features_1 JOIN games_features_1 ON \" \\\n",
    "    \"games_features_1.home_team_id = teams_features_1.team_id\")\n",
    "features = ['team_budget', 'score']\n",
    "assert set(features) == set(tmp.columns)\n",
    "assert tmp.count() == 49\n",
    "assert len(tmp.columns) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Running sql: SELECT * FROM teams_features_1 WHERE team_position < 5 against offline feature store"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.sql(\"SELECT * FROM teams_features_1 WHERE team_position < 5\")\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns\n",
    "for x in tmp.toPandas()[\"team_position\"].values:\n",
    "    assert x < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Running sql: SELECT * FROM teams_features_1 WHERE team_position < 5 against offline feature store"
     ]
    }
   ],
   "source": [
    "tmp = featurestore.sql(\"SELECT * FROM teams_features_1 WHERE team_position < 5\",\n",
    "                featurestore=featurestore.project_featurestore(), \n",
    "                 dataframe_type = \"spark\")\n",
    "assert len(tmp.columns) == 3\n",
    "assert \"team_budget\" in tmp.columns\n",
    "assert \"team_id\" in tmp.columns\n",
    "assert \"team_position\" in tmp.columns\n",
    "for x in tmp.toPandas()[\"team_position\"].values:\n",
    "    assert x < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Test Insert Operations in Existing Feature Groups, `featurestore.insert_into_featuregroup()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(spark.sparkContext)\n",
    "schema = StructType([StructField(\"equipo_id\", IntegerType(), True),\n",
    "                     StructField(\"equipo_presupuesto\", FloatType(), True),\n",
    "                     StructField(\"equipo_posicion\", IntegerType(), True)\n",
    "                        ])\n",
    "sample_df = sqlContext.createDataFrame([(999, 41251.52, 1), (998, 1319.4, 8), (997, 21219.1, 2)], schema)\n",
    "insert_count = sample_df.count()\n",
    "assert insert_count == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM teams_features_spanish_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "spanish_team_features_df = featurestore.get_featuregroup(\n",
    "    \"teams_features_spanish\")\n",
    "pre_insert_count = spanish_team_features_df.count()\n",
    "assert pre_insert_count == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data into offline feature group teams_features_spanish...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Inserting data into offline feature group teams_features_spanish... [COMPLETE]\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM teams_features_spanish_1 against offline feature store\n",
      "Insertion into feature group was successful\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM teams_features_spanish_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    sample_df, \n",
    "    \"teams_features_spanish\"\n",
    ")\n",
    "spanish_team_features_df_updated = featurestore.get_featuregroup(\n",
    "    \"teams_features_spanish\")\n",
    "\n",
    "after_insert_count = spanish_team_features_df_updated.count()\n",
    "assert after_insert_count == 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    sample_df, \n",
    "    \"teams_features_spanish\", \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    featuregroup_version=1, \n",
    "    mode=\"append\"\n",
    ")\n",
    "\n",
    "after_insert_count2 = featurestore.get_featuregroup(\"teams_features_spanish\").count()\n",
    "assert after_insert_count2 == 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data into offline feature group teams_features_spanish...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Inserting data into offline feature group teams_features_spanish... [COMPLETE]\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM teams_features_spanish_1 against offline feature store\n",
      "Insertion into feature group was successful\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM teams_features_spanish_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    sample_df, \n",
    "    \"teams_features_spanish\",\n",
    "    mode=\"overwrite\")\n",
    "\n",
    "count_after_overwrite = featurestore.get_featuregroup(\"teams_features_spanish\").count()\n",
    "assert count_after_overwrite == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test integration of feature store with Numpy, Pandas and plain Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 2 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id` against offline feature store"
     ]
    }
   ],
   "source": [
    "pandas_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], dataframe_type=\"pandas\")\n",
    "assert \"team_budget\" in pandas_df.columns.values\n",
    "assert \"average_attendance\" in pandas_df.columns.values\n",
    "assert len(pandas_df) == 50\n",
    "assert len(pandas_df.columns.values) == 2\n",
    "assert isinstance(pandas_df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 2 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id` against offline feature store"
     ]
    }
   ],
   "source": [
    "numpy_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], \n",
    "                                      dataframe_type=\"numpy\")\n",
    "assert numpy_df.shape[0] == 50\n",
    "assert numpy_df.shape[1] == 2\n",
    "assert isinstance(numpy_df, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 2 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id` against offline feature store"
     ]
    }
   ],
   "source": [
    "python_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], \n",
    "                                      dataframe_type=\"python\")\n",
    "assert len(python_df) == 50\n",
    "assert isinstance(python_df, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 2 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget, average_attendance FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id` against offline feature store"
     ]
    }
   ],
   "source": [
    "spark_df = featurestore.get_features([\"team_budget\", \"average_attendance\"], \n",
    "                                      dataframe_type=\"spark\")\n",
    "assert spark_df.count() == 50\n",
    "assert isinstance(spark_df, DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering feature metadata...\n",
      "Registering feature metadata... [COMPLETE]\n",
      "Writing feature data to offline feature group (Hive)...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Writing feature data to offline feature group (Hive)... [COMPLETE]\n",
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "# Let's rename the columns to differentiate this feature group from existing ones in the feature store\n",
    "pandas_df.columns = [\"team_budget_test\", \"average_attendance_test\"]\n",
    "\n",
    "featurestore.create_featuregroup(\n",
    "    pandas_df,\n",
    "    \"pandas_test_example\",\n",
    "    description=\"test featuregroup created from pandas dataframe\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "assert \"pandas_test_example_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "insert_into_featuregroup() got an unexpected keyword argument 'descriptive_statistics'\n",
      "Traceback (most recent call last):\n",
      "TypeError: insert_into_featuregroup() got an unexpected keyword argument 'descriptive_statistics'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_pre_pandas_insert_overwrite = featurestore.get_featuregroup(\"pandas_test_example\").count()\n",
    "featurestore.insert_into_featuregroup(\n",
    "    pandas_df, \n",
    "    \"pandas_test_example\",\n",
    "    descriptive_statistics=False, \n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    mode=\"overwrite\")\n",
    "count_after_pandas_insert_overwrite = featurestore.get_featuregroup(\"pandas_test_example\").count()\n",
    "assert count_pre_pandas_insert_overwrite == count_after_pandas_insert_overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering feature metadata...\n",
      "Registering feature metadata... [COMPLETE]\n",
      "Writing feature data to offline feature group (Hive)...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Writing feature data to offline feature group (Hive)... [COMPLETE]\n",
      "Feature group created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    numpy_df,\n",
    "    \"numpy_test_example\",\n",
    "    description=\"test featuregroup created from numpy matrix\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "assert \"numpy_test_example_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM numpy_test_example_1 against offline feature store\n",
      "Inserting data into offline feature group numpy_test_example...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Inserting data into offline feature group numpy_test_example... [COMPLETE]\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM numpy_test_example_1 against offline feature store\n",
      "Insertion into feature group was successful\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM numpy_test_example_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "numpy_test_df_count_pre_insert_overwrite = featurestore.get_featuregroup(\"numpy_test_example\", dataframe_type=\"spark\").count()\n",
    "featurestore.insert_into_featuregroup(\n",
    "    numpy_df, \n",
    "    \"numpy_test_example\",\n",
    "\n",
    "    mode=\"overwrite\")\n",
    "numpy_test_df_count_after_insert_overwrite = featurestore.get_featuregroup(\"numpy_test_example\", dataframe_type=\"spark\").count()\n",
    "assert numpy_test_df_count_pre_insert_overwrite == numpy_test_df_count_pre_insert_overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering feature metadata...\n",
      "Registering feature metadata... [COMPLETE]\n",
      "Writing feature data to offline feature group (Hive)...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Writing feature data to offline feature group (Hive)... [COMPLETE]\n",
      "Feature group created successfully\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM python_test_example_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "featurestore.create_featuregroup(\n",
    "    python_df,\n",
    "    \"python_test_example\",\n",
    "    description=\"test featuregroup created from python 2D list\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False\n",
    ")\n",
    "\n",
    "python_test_df_count_pre_insert_overwrite = featurestore.get_featuregroup(\"python_test_example\", dataframe_type=\"spark\").count()\n",
    "assert \"python_test_example_1\" in featurestore.get_featuregroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data into offline feature group python_test_example...\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Inserting data into offline feature group python_test_example... [COMPLETE]\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM python_test_example_1 against offline feature store\n",
      "Insertion into feature group was successful\n",
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM python_test_example_1 against offline feature store"
     ]
    }
   ],
   "source": [
    "featurestore.insert_into_featuregroup(\n",
    "    python_df, \n",
    "    \"python_test_example\",\n",
    "    mode=\"overwrite\")\n",
    "\n",
    "python_test_df_count_after_insert_overwrite = featurestore.get_featuregroup(\"python_test_example\", dataframe_type=\"spark\").count()\n",
    "assert python_test_df_count_pre_insert_overwrite == python_test_df_count_after_insert_overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test update Feature Store Statistics `featurestore.update_featuregroup_stats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM teams_features_1 against offline feature store\n",
      "computing descriptive statistics for : teams_features, version: 1\n",
      "computing feature correlation for: teams_features, version: 1\n",
      "computing feature histograms for: teams_features, version: 1\n",
      "computing cluster analysis for: teams_features, version: 1"
     ]
    }
   ],
   "source": [
    "featurestore.update_featuregroup_stats(\"teams_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT * FROM teams_features_1 against offline feature store\n",
      "computing descriptive statistics for : teams_features, version: 1\n",
      "computing feature correlation for: teams_features, version: 1\n",
      "computing feature histograms for: teams_features, version: 1\n",
      "computing cluster analysis for: teams_features, version: 1"
     ]
    }
   ],
   "source": [
    "featurestore.update_featuregroup_stats(\n",
    "    \"teams_features\", \n",
    "    featuregroup_version=1, \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    descriptive_statistics=True,\n",
    "    feature_correlation=True, \n",
    "    feature_histograms=True,\n",
    "    cluster_analysis=True,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Write Training Dataset Operations \n",
    "\n",
    "- `featurestore.get_latest_training_dataset_version()`\n",
    "- `create_training_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sql: use ittests_featurestore against offline feature store\n",
      "Logical query plan for getting 3 features from the featurestore created successfully\n",
      "SQL string for the query created successfully\n",
      "Running sql: SELECT team_budget, average_attendance, team_position FROM teams_features_1 JOIN attendances_features_1 ON teams_features_1.`team_id`=attendances_features_1.`team_id` against offline feature store"
     ]
    }
   ],
   "source": [
    "features_df = featurestore.get_features(\n",
    "    [\"team_budget\", \"average_attendance\",\n",
    "    \"team_position\"]\n",
    ")\n",
    "latest_version = featurestore.get_latest_training_dataset_version(\"team_position_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write feature frame, write_mode: overwrite\n",
      "Training Dataset created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    training_dataset_version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_csv\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"csv\",\n",
    "    training_dataset_version= 1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_tsv\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"tsv\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_parquet\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"parquet\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_orc\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"orc\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_avro\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"avro\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset created successfully\n",
      "/srv/hops/anaconda/anaconda/envs/ittests/lib/python3.6/site-packages/hops/featurestore_impl/featureframes/FeatureFrame.py:464: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  hdf5_file = h5py.File(tf)"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_hdf5\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"hdf5\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset created successfully"
     ]
    }
   ],
   "source": [
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_npy\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"npy\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset created successfully"
     ]
    }
   ],
   "source": [
    "# Petastorm is only supported in python 3\n",
    "\n",
    "PetastormSchema = Unischema('team_position_prediction_petastorm_schema', [\n",
    "    UnischemaField('team_budget', np.float32, (), ScalarCodec(FloatType()), False),\n",
    "    UnischemaField('average_attendance', np.float32, (), ScalarCodec(FloatType()), False),\n",
    "    UnischemaField('team_position', np.int32, (), ScalarCodec(IntegerType()), False)\n",
    "])\n",
    "\n",
    "petastorm_args = {\n",
    "    \"schema\": PetastormSchema\n",
    "}\n",
    "\n",
    "featurestore.create_training_dataset(\n",
    "    features_df, \"team_position_prediction_petastorm\",\n",
    "    description=\"a dataset with features for football teams, used for training a model to predict league-position\",\n",
    "    featurestore=featurestore.project_featurestore(),\n",
    "    data_format=\"petastorm\",\n",
    "    training_dataset_version=1,\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    stat_columns=None,\n",
    "    petastorm_args=petastorm_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = featurestore.get_training_datasets()\n",
    "assert 'team_position_prediction_1' in tds\n",
    "assert 'team_position_prediction_csv_1' in tds\n",
    "assert 'team_position_prediction_tsv_1' in tds\n",
    "assert 'team_position_prediction_parquet_1' in tds\n",
    "assert 'team_position_prediction_orc_1' in tds\n",
    "assert 'team_position_prediction_avro_1' in tds\n",
    "assert 'team_position_prediction_hdf5_1'in tds\n",
    "assert 'team_position_prediction_npy_1' in tds\n",
    "assert 'team_position_prediction_petastorm_1' in tds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Insert into an existing training dataset, `featurestore.insert_into_training_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert_into_training_dataset\n",
      "Writing Feature Frame, data format: csv\n",
      "Insertion into training dataset was successful"
     ]
    }
   ],
   "source": [
    "count_pre_insert = featurestore.get_training_dataset(\"team_position_prediction_csv\").count()\n",
    "featurestore.insert_into_training_dataset(\n",
    "    features_df, \n",
    "    \"team_position_prediction_csv\",\n",
    "    descriptive_statistics=False,\n",
    "    feature_correlation=False,\n",
    "    feature_histograms=False,\n",
    "    cluster_analysis=False,\n",
    "    training_dataset_version=featurestore.get_latest_training_dataset_version(\"team_position_prediction_csv\")\n",
    ")\n",
    "count_after_insert = featurestore.get_training_dataset(\"team_position_prediction_csv\").count()\n",
    "assert count_pre_insert == count_after_insert # td only support overwrites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Training Dataset Utility Methods\n",
    "\n",
    "- `featurestore.get_training_dataset_path()`\n",
    "- `featurestore.get_training_dataset_tf_record_schema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hdfs.project_path() in featurestore.get_training_dataset_path(\"team_position_prediction_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hdfs.project_name() + \"_Training_Datasets\" in featurestore.get_training_dataset_path(\"team_position_prediction_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"team_position_prediction_csv\" in featurestore.get_training_dataset_path(\"team_position_prediction_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_schema = featurestore.get_training_dataset_tf_record_schema(\"team_position_prediction\")\n",
    "assert tf_schema == {'team_budget': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'average_attendance': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'team_position': tf.FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = featurestore.get_training_dataset(\"team_position_prediction\")\n",
    "tf_schema = featurestore.get_dataframe_tf_record_schema(features_df)\n",
    "assert tf_schema == {'team_budget': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'average_attendance': tf.FixedLenFeature(shape=[], dtype=tf.float32, default_value=None), \n",
    "                     'team_position': tf.FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test update Training Dataset stats\n",
    "\n",
    "- `featurestore.update_training_dataset_stats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : team_position_prediction, version: 1\n",
      "computing feature correlation for: team_position_prediction, version: 1\n",
      "computing feature histograms for: team_position_prediction, version: 1\n",
      "computing cluster analysis for: team_position_prediction, version: 1"
     ]
    }
   ],
   "source": [
    "featurestore.update_training_dataset_stats(\"team_position_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing descriptive statistics for : team_position_prediction, version: 1\n",
      "computing feature correlation for: team_position_prediction, version: 1\n",
      "computing feature histograms for: team_position_prediction, version: 1\n",
      "computing cluster analysis for: team_position_prediction, version: 1"
     ]
    }
   ],
   "source": [
    "featurestore.update_training_dataset_stats(\n",
    "    \"team_position_prediction\", \n",
    "    training_dataset_version=1, \n",
    "    featurestore=featurestore.project_featurestore(), \n",
    "    descriptive_statistics=True,\n",
    "    feature_correlation=True, \n",
    "    feature_histograms=True,\n",
    "    cluster_analysis=True,\n",
    "    stat_columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Read Training Datasets API `featurestore.get_training_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['team_budget', 'average_attendance', 'team_position']\n",
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_csv\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_hdf5\")\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_petastorm\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_avro\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_orc\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_tsv\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_npy\")\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = featurestore.get_training_dataset(\"team_position_prediction_parquet\")\n",
    "assert set(tmp.columns) == set(cols)\n",
    "assert tmp.count() == 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Featurestore Get Statistics\n",
    "\n",
    "- `featurestore.get_featuregroup_statistics()`\n",
    "- `featurestore.get_training_dataset_statistics()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = featurestore.get_featuregroup_statistics(\"teams_features\")\n",
    "assert not stats.cluster_analysis is None\n",
    "assert not stats.cluster_analysis.clusters is None\n",
    "assert not stats.cluster_analysis.datapoints is None\n",
    "assert len(stats.cluster_analysis.clusters) == len(stats.cluster_analysis.datapoints)\n",
    "assert not stats.cluster_analysis.clusters[0].datapoint_name is None\n",
    "assert not stats.cluster_analysis.clusters[0].cluster is None\n",
    "assert not stats.correlation_matrix is None\n",
    "assert not stats.correlation_matrix.feature_correlations is None\n",
    "assert len(stats.correlation_matrix.feature_correlations) > 0\n",
    "assert len(stats.correlation_matrix.feature_correlations) < constants.FEATURE_STORE.MAX_CORRELATION_MATRIX_COLUMNS\n",
    "assert not stats.correlation_matrix.feature_correlations[0].feature_name is None\n",
    "assert not stats.correlation_matrix.feature_correlations[0].correlation_values is None\n",
    "assert len(stats.correlation_matrix.feature_correlations[0].correlation_values) == \\\n",
    "len(stats.correlation_matrix.feature_correlations)\n",
    "assert not stats.descriptive_stats is None\n",
    "assert not stats.descriptive_stats.descriptive_stats is None\n",
    "assert len(stats.descriptive_stats.descriptive_stats) > 0\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].feature_name is None\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values is None\n",
    "assert len(stats.descriptive_stats.descriptive_stats[0].metric_values) > 0\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values[0].metric_name is None\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values[0].value is None\n",
    "assert not stats.feature_histograms is None\n",
    "assert not stats.feature_histograms.feature_distributions is None\n",
    "assert len(stats.feature_histograms.feature_distributions) > 0\n",
    "assert not stats.feature_histograms.feature_distributions[0].feature_name is None\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution is None\n",
    "assert len(stats.feature_histograms.feature_distributions[0].frequency_distribution) > 0\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution[0].bin is None\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution[0].frequency is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = featurestore.get_training_dataset_statistics(\"team_position_prediction\")\n",
    "assert not stats.cluster_analysis is None\n",
    "assert not stats.cluster_analysis.clusters is None\n",
    "assert not stats.cluster_analysis.datapoints is None\n",
    "assert len(stats.cluster_analysis.clusters) == len(stats.cluster_analysis.datapoints)\n",
    "assert not stats.cluster_analysis.clusters[0].datapoint_name is None\n",
    "assert not stats.cluster_analysis.clusters[0].cluster is None\n",
    "assert not stats.correlation_matrix is None\n",
    "assert not stats.correlation_matrix.feature_correlations is None\n",
    "assert len(stats.correlation_matrix.feature_correlations) > 0\n",
    "assert len(stats.correlation_matrix.feature_correlations) < constants.FEATURE_STORE.MAX_CORRELATION_MATRIX_COLUMNS\n",
    "assert not stats.correlation_matrix.feature_correlations[0].feature_name is None\n",
    "assert not stats.correlation_matrix.feature_correlations[0].correlation_values is None\n",
    "assert len(stats.correlation_matrix.feature_correlations[0].correlation_values) == len(stats.correlation_matrix.feature_correlations)\n",
    "assert not stats.descriptive_stats is None\n",
    "assert not stats.descriptive_stats.descriptive_stats is None\n",
    "assert len(stats.descriptive_stats.descriptive_stats) > 0\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].feature_name is None\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values is None\n",
    "assert len(stats.descriptive_stats.descriptive_stats[0].metric_values) > 0\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values[0].metric_name is None\n",
    "assert not stats.descriptive_stats.descriptive_stats[0].metric_values[0].value is None\n",
    "assert not stats.feature_histograms is None\n",
    "assert not stats.feature_histograms.feature_distributions is None\n",
    "assert len(stats.feature_histograms.feature_distributions) > 0\n",
    "assert not stats.feature_histograms.feature_distributions[0].feature_name is None\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution is None\n",
    "assert len(stats.feature_histograms.feature_distributions[0].frequency_distribution) > 0\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution[0].bin is None\n",
    "assert not stats.feature_histograms.feature_distributions[0].frequency_distribution[0].frequency is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Featurestore Visualizations\n",
    "\n",
    "- `featurestore.visualize_featuregroup_distributions()`\n",
    "- `featurestore.visualize_featuregroup_correlations()`\n",
    "- `featurestore.visualize_featuregroup_clusters()`\n",
    "- `featurestore.visualize_featuregroup_descriptive_stats()`\n",
    "- `featurestore.visualize_training_dataset_distributions()`\n",
    "- `featurestore.visualize_training_dataset_correlations()`\n",
    "- `featurestore.visualize_traniing_dataset_clusters()`\n",
    "- `featurestore.visualize_training_dataset_descriptive_stats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = featurestore.visualize_featuregroup_distributions(\"teams_features\", plot=False)\n",
    "fig.savefig(\"teams_features_distributions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = featurestore.visualize_featuregroup_correlations(\"teams_features\", plot=False)\n",
    "fig.savefig(\"teams_features_correlations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = featurestore.visualize_featuregroup_clusters(\"teams_features\", plot=False)\n",
    "fig.savefig(\"teams_features_clusters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_stats_df = featurestore.visualize_featuregroup_descriptive_stats(\"teams_features\")\n",
    "desc_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = featurestore.visualize_training_dataset_distributions(\"team_position_prediction\", plot=False)\n",
    "fig.savefig(\"team_position_prediction_distributions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = featurestore.visualize_training_dataset_correlations(\"team_position_prediction\", plot=False)\n",
    "fig.savefig(\"team_position_prediction_correlations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = featurestore.visualize_training_dataset_clusters(\"team_position_prediction\", plot=False)\n",
    "fig.savefig(\"team_position_prediction_clusters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_stats_df = featurestore.visualize_training_dataset_descriptive_stats(\"team_position_prediction\")\n",
    "desc_stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleanup (Delete FS Contents so that next test run works the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete feature groups\n",
    "spark.sql('use ' + featurestore.project_featurestore())\n",
    "for fg in featurestore.get_featuregroups():\n",
    "    try:\n",
    "        spark.sql(\"drop table \" + fg)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete training datasets\n",
    "td_dir = hdfs.project_name() + \"_Training_Datasets/\"\n",
    "for td in featurestore.get_training_datasets():\n",
    "    try:\n",
    "        hdfs.rmr(td_dir + td)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.get_featurestore_metadata(update_cache=True)\n",
    "# on demand feature group will still be there.. maybe add delete endpoint in the python SDK?\n",
    "#assert featurestore.get_featuregroups() == [] \n",
    "assert featurestore.get_training_datasets() == []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Metadata operations of Feature Groups, \n",
    "\n",
    "- `featurestore.add_metadata()`, \n",
    "- `featurestore.get_metadata()`, \n",
    "- `featurestore.remove_metadata()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore.add_metadata(\"teams_features\", {\"attr1\" : \"attr1 value\", \"attr2\" : \"attr2 value\"})\n",
    "md = featurestore.get_metadata(\"teams_features\", [\"attr1\"])\n",
    "assert len(md) == 1\n",
    "assert md[\"attr1\"] == \"attr1 value\"\n",
    "md = featurestore.get_metadata(\"teams_features\")\n",
    "assert len(md) == 2\n",
    "assert md[\"attr1\"] == \"attr1 value\"\n",
    "assert md[\"attr2\"] == \"attr2 value\"\n",
    "featurestore.remove_metadata(\"teams_features\", [\"attr1\"])\n",
    "md = featurestore.get_metadata(\"teams_features\")\n",
    "assert len(md) == 1\n",
    "assert md[\"attr2\"] == \"attr2 value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test default config \n",
    "\n",
    "- `kafka.get_default_config()`, \n",
    "- `kafka.get_security_protocol()`,\n",
    "- `kafka.get_broker_endpoints_list()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = kafka.get_kafka_default_config()\n",
    "assert \"bootstrap.servers\" in config\n",
    "assert \"security.protocol\" in config\n",
    "assert \"ssl.ca.location\" in config\n",
    "assert \"ssl.key.location\" in config\n",
    "assert \"ssl.certificate.location\" in config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(kafka.get_security_protocol()) > 0\n",
    "assert len(kafka.get_broker_endpoints_list()) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLS Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test access to TLS tokens\n",
    "\n",
    "- `tls.get_key_store()`\n",
    "- `tls.get_trust_store()`\n",
    "- `tls.get_key_store_pwd()`\n",
    "- `tls.get_trust_store_pwd()`\n",
    "- `tls.get_client_certificate_location()`\n",
    "- `tls.get_client_key_location()`\n",
    "- `tls.get_ca_chain_location()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tls.get_key_store()) > 0\n",
    "assert len(tls.get_trust_store()) > 0\n",
    "assert len(tls.get_key_store_pwd()) > 0\n",
    "assert len(tls.get_trust_store_pwd()) > 0\n",
    "assert len(tls.get_client_certificate_location()) > 0\n",
    "assert len(tls.get_client_key_location()) > 0\n",
    "assert len(tls.get_ca_chain_location()) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving Tests\n",
    "\n",
    "These tests require that you have the following files in the Resources directory:\n",
    "\n",
    "- `iris_model.knn`\n",
    "- `iris_flower_classifier.py`\n",
    "- `mnist`\n",
    "\n",
    "Where mnist is a directory containing a tensorflow model.\n",
    "\n",
    "These files can be downloaded from here: `http://snurran.sics.se/hops/hops-util-py_test/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Export Model HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model IrisFlowerClassifier as version 1 successfully.\n",
      "Polling IrisFlowerClassifier version 1 for model availability.\n",
      "Model now available.\n",
      "Exported model IrisFlowerClassifier as version 2 successfully.\n",
      "Polling IrisFlowerClassifier version 2 for model availability.\n",
      "Model now available.\n",
      "Exported model IrisFlowerClassifier as version 3 successfully.\n",
      "Polling IrisFlowerClassifier version 3 for model availability.\n",
      "Model now available.\n",
      "Exported model IrisFlowerClassifier as version 4 successfully.\n",
      "Polling IrisFlowerClassifier version 4 for model availability.\n",
      "Model now available.\n",
      "Exported model IrisFlowerClassifier as version 5 successfully.\n",
      "Polling IrisFlowerClassifier version 5 for model availability.\n",
      "Model now available.\n",
      "Exported model IrisFlowerClassifier_abs as version 1 successfully.\n",
      "Polling IrisFlowerClassifier_abs version 1 for model availability.\n",
      "Model now available.\n",
      "Exported model IrisFlowerClassifier_abs as version 2 successfully.\n",
      "Polling IrisFlowerClassifier_abs version 2 for model availability.\n",
      "Model now available.\n",
      "Exported model IrisFlowerClassifier_abs as version 3 successfully.\n",
      "Polling IrisFlowerClassifier_abs version 3 for model availability.\n",
      "Model now available.\n",
      "Exported model IrisFlowerClassifier_abs as version 4 successfully.\n",
      "Polling IrisFlowerClassifier_abs version 4 for model availability.\n",
      "Model now available.\n",
      "Exported model IrisFlowerClassifier_abs as version 5 successfully.\n",
      "Polling IrisFlowerClassifier_abs version 5 for model availability.\n",
      "Model now available."
     ]
    }
   ],
   "source": [
    "model_path_relative = \"Resources\"\n",
    "\n",
    "model.export(model_path_relative, \"IrisFlowerClassifier\", model_version=1, overwrite=True)\n",
    "model.export(model_path_relative, \"IrisFlowerClassifier\", model_version=2, overwrite=True, metrics={'accuracy': 21.5, 'loss': 31.3})\n",
    "model.export(model_path_relative, \"IrisFlowerClassifier\", model_version=3, overwrite=True, metrics={'accuracy': 0.5})\n",
    "model.export(model_path_relative, \"IrisFlowerClassifier\", model_version=4, overwrite=True, metrics={'accuracy': 9})\n",
    "model.export(model_path_relative, \"IrisFlowerClassifier\", model_version=5, overwrite=True, metrics={'accuracy': 30})\n",
    "\n",
    "model_path_abs = hdfs.project_path() + \"Resources\"\n",
    "\n",
    "model.export(model_path_abs, \"IrisFlowerClassifier_abs\", metrics={'accuracy': 10.9})\n",
    "model.export(model_path_abs, \"IrisFlowerClassifier_abs\", metrics={'accuracy': 21.5, 'loss': 31.3})\n",
    "model.export(model_path_abs, \"IrisFlowerClassifier_abs\", metrics={'accuracy': 0.5})\n",
    "model.export(model_path_abs, \"IrisFlowerClassifier_abs\")\n",
    "model.export(model_path_abs, \"IrisFlowerClassifier_abs\", metrics={'accuracy': 30})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Export Model Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying local path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/model/model.pb to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Models/local_model_dir/1\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Exported model local_model_dir as version 1 successfully.\n",
      "Polling local_model_dir version 1 for model availability.\n",
      "Model now available.\n",
      "Started copying local path model/model.pb to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Models/local_model_dir/2\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Exported model local_model_dir as version 2 successfully.\n",
      "Polling local_model_dir version 2 for model availability.\n",
      "Model now available.\n",
      "Started copying local path /srv/hops/hopsdata/tmp/nm-local-dir/usercache/6rleftXNS7jE4GPq0aancNC_IQkiuF3dRnRBytwdAR4/appcache/application_1576760828949_0038/container_e01_1576760828949_0038_01_000001/model/model.pb to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Models/local_model_file/1\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Exported model local_model_file as version 1 successfully.\n",
      "Polling local_model_file version 1 for model availability.\n",
      "Model now available."
     ]
    }
   ],
   "source": [
    "local_model_dir = os.getcwd() + '/model'\n",
    "local_model_file = local_model_dir + '/model.pb'\n",
    "if not os.path.exists(local_model_dir):\n",
    "    os.mkdir(local_model_dir)\n",
    "    f = open(local_model_file, \"w\")\n",
    "    f.write(\"model\")\n",
    "    f.close()\n",
    "    \n",
    "model.export(local_model_dir, 'local_model_dir')\n",
    "model.export('model', 'local_model_dir')\n",
    "\n",
    "model.export(local_model_file, 'local_model_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.export(model_path_relative, \"IrisFlowerClassifier\", model_version=4, overwrite=True, metrics={'accuracy': \"not number\"})\n",
    "    assert False\n",
    "except AssertionError:\n",
    "    assert True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.export(model_path_abs, \"IrisFlowerClassifier\", model_version=4, overwrite=True, metrics={1337: \"0.5\"})\n",
    "    assert False\n",
    "except AssertionError:\n",
    "    assert True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hdfs.exists(\"Models/IrisFlowerClassifier/1/iris_knn.pkl\")\n",
    "assert hdfs.exists(\"Models/IrisFlowerClassifier/1/iris_flower_classifier.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'modelDTO', 'href': 'https://hopsworks0.logicalclocks.com:8181/hopsworks-api/api/project/120/models/IrisFlowerClassifier_5', 'created': 1576776038946, 'description': 'A collection of models for IrisFlowerClassifier', 'environment': ['Models/IrisFlowerClassifier/5/environment_cpu_1576776042073.yml'], 'experimentId': 'application_1576760828949_0038_73', 'id': 'IrisFlowerClassifier_5', 'metrics': {'accuracy': '30'}, 'name': 'IrisFlowerClassifier', 'program': 'Models/IrisFlowerClassifier/5/program.ipynb', 'userFullName': 'Admin Admin', 'version': 5}"
     ]
    }
   ],
   "source": [
    "best_model = model.get_best_model(\"IrisFlowerClassifier\", 'accuracy', Metric.MAX)\n",
    "print(best_model)\n",
    "assert best_model['name'] == \"IrisFlowerClassifier\"\n",
    "assert best_model['version'] == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'modelDTO', 'href': 'https://hopsworks0.logicalclocks.com:8181/hopsworks-api/api/project/120/models/IrisFlowerClassifier_3', 'created': 1576776022276, 'description': 'A collection of models for IrisFlowerClassifier', 'environment': ['Models/IrisFlowerClassifier/3/environment_cpu_1576776025357.yml'], 'experimentId': 'application_1576760828949_0038_73', 'id': 'IrisFlowerClassifier_3', 'metrics': {'accuracy': '0.5'}, 'name': 'IrisFlowerClassifier', 'program': 'Models/IrisFlowerClassifier/3/program.ipynb', 'userFullName': 'Admin Admin', 'version': 3}"
     ]
    }
   ],
   "source": [
    "best_model = model.get_best_model(\"IrisFlowerClassifier\", 'accuracy', Metric.MIN)\n",
    "print(best_model)\n",
    "assert best_model['name'] == \"IrisFlowerClassifier\"\n",
    "assert best_model['version'] == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    best_model = model.get_best_model(\"not_exist\", 'accuracy', Metric.MIN)\n",
    "    assert False\n",
    "except model.ModelNotFound:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    best_model = model.get_best_model(\"IrisFlowerClassifier\", 'not_exist', Metric.MIN)\n",
    "    assert False\n",
    "except model.ModelNotFound:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.get_model(\"mnist\", 3)\n",
    "    assert False\n",
    "except model.ModelNotFound:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"Resources/mnist/1\"\n",
    "model.export(model_path, \"mnist\", model_version=1, overwrite=True)\n",
    "model_path = \"Resources/mnist/2\"\n",
    "model.export(model_path, \"mnist\", model_version=2, overwrite=True)\n",
    "assert hdfs.exists(\"Models/mnist/1\")\n",
    "assert hdfs.exists(\"Models/mnist/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Serve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting serving with name: IrisFlowerClassifier...\n",
      "Serving with name: IrisFlowerClassifier successfully deleted\n",
      "Creating a serving for model IrisFlowerClassifier ...\n",
      "Serving for model IrisFlowerClassifier successfully created"
     ]
    }
   ],
   "source": [
    "script_path = \"Models/IrisFlowerClassifier/1/iris_flower_classifier.py\"\n",
    "serving.exists(\"IrisFlowerClassifier\")\n",
    "if serving.exists(\"IrisFlowerClassifier\"):\n",
    "    serving.delete(\"IrisFlowerClassifier\")\n",
    "serving.create_or_update(script_path, \"IrisFlowerClassifier\", serving_type=\"SKLEARN\", \n",
    "                                 model_version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert serving.exists(\"IrisFlowerClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a serving for model mnist ...\n",
      "Serving for model mnist successfully created"
     ]
    }
   ],
   "source": [
    "model_path = \"Models/mnist/2/\"\n",
    "if serving.exists(\"mnist\"):\n",
    "    serving.delete(\"mnist\")\n",
    "serving.create_or_update(model_path, \"mnist\", serving_type=\"TENSORFLOW\", \n",
    "                                 model_version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert serving.exists(\"mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Data Access Operations on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert serving.get_id(\"IrisFlowerClassifier\") is not None\n",
    "assert serving.get_id(\"mnist\") is not None\n",
    "assert \"Models/IrisFlowerClassifier/1/iris_flower_classifier.py\" in serving.get_artifact_path(\"IrisFlowerClassifier\")\n",
    "assert \"Models/mnist/2/\" in serving.get_artifact_path(\"mnist\")\n",
    "assert serving.get_type(\"IrisFlowerClassifier\") == \"SKLEARN\"\n",
    "assert serving.get_type(\"mnist\") == \"TENSORFLOW\"\n",
    "assert serving.get_version(\"IrisFlowerClassifier\") == 1\n",
    "assert serving.get_version(\"mnist\") == 2\n",
    "assert serving.get_kafka_topic(\"IrisFlowerClassifier\") is not None\n",
    "assert serving.get_kafka_topic(\"mnist\") is not None\n",
    "assert serving.get_status(\"IrisFlowerClassifier\") == \"Stopped\"\n",
    "assert serving.get_status(\"mnist\") == \"Stopped\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Start/Stop Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting serving with name: IrisFlowerClassifier...\n",
      "Serving with name: IrisFlowerClassifier successfully started\n",
      "Starting serving with name: mnist...\n",
      "Serving with name: mnist successfully started"
     ]
    }
   ],
   "source": [
    "serving.start(\"IrisFlowerClassifier\")\n",
    "serving.start(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert serving.get_status(\"IrisFlowerClassifier\") == \"Running\"\n",
    "assert serving.get_status(\"mnist\") == \"Running\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping serving with name: IrisFlowerClassifier...\n",
      "Serving with name: IrisFlowerClassifier successfully stopped\n",
      "Stopping serving with name: mnist...\n",
      "Serving with name: mnist successfully stopped"
     ]
    }
   ],
   "source": [
    "serving.stop(\"IrisFlowerClassifier\")\n",
    "serving.stop(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert serving.get_status(\"IrisFlowerClassifier\") == \"Stopped\"\n",
    "assert serving.get_status(\"mnist\") == \"Stopped\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Send Inference Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting serving with name: IrisFlowerClassifier...\n",
      "Serving with name: IrisFlowerClassifier successfully started\n",
      "Starting serving with name: mnist...\n",
      "Serving with name: mnist successfully started"
     ]
    }
   ],
   "source": [
    "serving.start(\"IrisFlowerClassifier\")\n",
    "serving.start(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not create or update serving (url: /hopsworks-api/api/project/120/inference/models/IrisFlowerClassifier:predict), server response: \n",
      " HTTP code: 500, HTTP reason: Internal Server Error, error code: 250007, error msg: Serving instance internal error, user msg: <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n",
      "<title>500 Internal Server Error</title>\n",
      "<h1>Internal Server Error</h1>\n",
      "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 527, in make_inference_request\n",
      "    return _make_inference_request_rest(serving_name, data, verb)\n",
      "  File \"/srv/hops/anaconda/anaconda/envs/python36/lib/python3.6/site-packages/hops/serving.py\", line 562, in _make_inference_request_rest\n",
      "    error_code, error_msg, user_msg))\n",
      "hops.exceptions.RestAPIError: Could not create or update serving (url: /hopsworks-api/api/project/120/inference/models/IrisFlowerClassifier:predict), server response: \n",
      " HTTP code: 500, HTTP reason: Internal Server Error, error code: 250007, error msg: Serving instance internal error, user msg: <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n",
      "<title>500 Internal Server Error</title>\n",
      "<h1>Internal Server Error</h1>\n",
      "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    data = {\"inputs\" : [[random.uniform(1, 8) for i in range(4)]]}\n",
    "    response = serving.make_inference_request(\"IrisFlowerClassifier\", data)\n",
    "    print(response)\n",
    "    assert response is not None\n",
    "    assert \"predictions\" or \"prediction\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [[0.000496011868, 1.18008785e-08, 0.201137573, 0.580856144, 2.75102479e-07, 0.214045227, 0.00014854352, 4.37322706e-05, 0.00325523899, 1.73046719e-05]]}\n",
      "{'predictions': [[0.000641128456, 1.4078928e-09, 0.0745601952, 0.490354359, 8.57360305e-07, 0.387143135, 0.00227252091, 6.10170246e-05, 0.0447829627, 0.000183804674]]}\n",
      "{'predictions': [[0.000418708398, 2.07440487e-09, 0.145863384, 0.377752811, 1.90975516e-06, 0.469116181, 0.000256557396, 5.82233115e-05, 0.00651905406, 1.31911293e-05]]}\n",
      "{'predictions': [[4.32615634e-05, 2.3104592e-08, 0.115783177, 0.704663873, 1.35617867e-07, 0.174041361, 4.74509507e-05, 4.05858827e-06, 0.00541397836, 2.67096084e-06]]}\n",
      "{'predictions': [[0.00078638579, 8.21143598e-09, 0.357391894, 0.280190051, 1.31995034e-06, 0.35193646, 0.000322822307, 3.73325965e-05, 0.00927347504, 6.03416083e-05]]}\n",
      "{'predictions': [[0.00021984303, 5.10015497e-09, 0.081924893, 0.460112602, 3.47095443e-06, 0.427535713, 0.0067972932, 1.43612915e-05, 0.0232881252, 0.000103700622]]}\n",
      "{'predictions': [[0.000366424705, 1.90834086e-08, 0.140124917, 0.404699802, 3.36422136e-06, 0.426357895, 0.000627222063, 0.000545721618, 0.0270082131, 0.000266453339]]}\n",
      "{'predictions': [[0.000113636437, 7.37194528e-09, 0.25920108, 0.549697638, 8.88048476e-07, 0.18013075, 0.000272467616, 2.02767023e-05, 0.0105553959, 7.90310423e-06]]}\n",
      "{'predictions': [[9.45374777e-05, 6.53590337e-09, 0.399360985, 0.512139916, 5.91609677e-08, 0.0871225446, 5.71279888e-05, 1.01548903e-05, 0.00120780384, 6.84026963e-06]]}\n",
      "{'predictions': [[0.00105037249, 2.15729767e-09, 0.259245396, 0.252125949, 1.33481865e-06, 0.474740773, 0.000195962464, 0.000233907, 0.0120225046, 0.000383835053]]}\n",
      "{'predictions': [[7.01072859e-05, 6.194385e-09, 0.142895222, 0.366554558, 2.19687635e-07, 0.484826863, 0.000143465848, 1.48966692e-05, 0.00548892422, 5.73063198e-06]]}\n",
      "{'predictions': [[0.000345891254, 5.89791682e-09, 0.724375129, 0.234018207, 1.37340612e-06, 0.0369827151, 0.000328820664, 4.33508758e-05, 0.00389662082, 7.96147469e-06]]}\n",
      "{'predictions': [[0.00104751508, 2.63382621e-10, 0.113659911, 0.115466148, 1.36092058e-06, 0.76584512, 0.000515875232, 1.13681681e-05, 0.00342917605, 2.35859861e-05]]}\n",
      "{'predictions': [[9.54758289e-05, 4.58166571e-09, 0.230612591, 0.168687761, 8.11613248e-08, 0.593242049, 0.000377982622, 3.113709e-06, 0.00696799532, 1.30148555e-05]]}\n",
      "{'predictions': [[0.00110947737, 7.15120452e-09, 0.407531053, 0.208523497, 3.10034739e-05, 0.247089118, 0.00119523681, 0.000212500803, 0.133859992, 0.000447959115]]}\n",
      "{'predictions': [[0.000421535486, 2.40169218e-08, 0.0666727, 0.290992945, 1.19511037e-06, 0.633430421, 0.00135162927, 0.000307910872, 0.00669451291, 0.000127129344]]}\n",
      "{'predictions': [[0.000179610332, 1.62511089e-08, 0.311198324, 0.294510514, 5.11382382e-07, 0.384091973, 0.000567407522, 3.98394186e-05, 0.00937425066, 3.7525635e-05]]}\n",
      "{'predictions': [[0.000294897851, 2.94829738e-09, 0.130684301, 0.399182916, 5.08563653e-06, 0.3997311, 0.000562571, 2.76261017e-05, 0.0691126436, 0.000398830307]]}\n",
      "{'predictions': [[0.00104439619, 8.93610608e-09, 0.181378916, 0.540792167, 5.79827656e-06, 0.261965424, 0.000718652, 0.000145315818, 0.0137709919, 0.000178362476]]}\n",
      "{'predictions': [[0.000848210533, 2.3590685e-10, 0.236877, 0.130587235, 1.09693178e-06, 0.623515129, 0.000227176875, 3.15287325e-05, 0.00786467362, 4.79895498e-05]]}"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    data = {\n",
    "                \"signature_name\": 'predict_images',\n",
    "                \"instances\": [np.random.rand(784).tolist()]\n",
    "            }\n",
    "    response = serving.make_inference_request(\"mnist\", data)\n",
    "    print(response)\n",
    "    assert response is not None\n",
    "    assert \"predictions\" in response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Kafka Inference Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = serving.get_kafka_topic(\"IrisFlowerClassifier\")\n",
    "config = kafka.get_kafka_default_config()\n",
    "config['default.topic.config'] = {'auto.offset.reset': 'earliest'}\n",
    "consumer = Consumer(config)\n",
    "topics = [topic]\n",
    "consumer.subscribe(topics)\n",
    "json_schema = kafka.get_schema(topic)\n",
    "avro_schema = kafka.convert_json_schema_to_avro(json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    msg = consumer.poll(timeout=1.5)\n",
    "    if msg is not None:\n",
    "        value = msg.value()\n",
    "        event_dict = kafka.parse_avro_msg(value, avro_schema)\n",
    "        assert \"modelName\" in event_dict\n",
    "        assert \"requestTimestamp\" in event_dict\n",
    "        assert \"servingType\" in event_dict\n",
    "        assert \"inferenceResponse\" in event_dict\n",
    "        assert event_dict[\"modelName\"] == \"IrisFlowerClassifier\"\n",
    "        assert event_dict[\"servingType\"] == \"SKLEARN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = serving.get_kafka_topic(\"mnist\")\n",
    "config = kafka.get_kafka_default_config()\n",
    "config['default.topic.config'] = {'auto.offset.reset': 'earliest'}\n",
    "consumer = Consumer(config)\n",
    "topics = [topic]\n",
    "consumer.subscribe(topics)\n",
    "json_schema = kafka.get_schema(topic)\n",
    "avro_schema = kafka.convert_json_schema_to_avro(json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    msg = consumer.poll(timeout=1.5)\n",
    "    if msg is not None:\n",
    "        value = msg.value()\n",
    "        event_dict = kafka.parse_avro_msg(value, avro_schema)\n",
    "        assert \"modelName\" in event_dict\n",
    "        assert \"requestTimestamp\" in event_dict\n",
    "        assert \"servingType\" in event_dict\n",
    "        assert \"inferenceResponse\" in event_dict\n",
    "        assert event_dict[\"modelName\"] == \"mnist\"\n",
    "        assert event_dict[\"servingType\"] == \"TENSORFLOW\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Delete Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting serving with name: IrisFlowerClassifier...\n",
      "Serving with name: IrisFlowerClassifier successfully deleted\n",
      "Deleting serving with name: mnist...\n",
      "Serving with name: mnist successfully deleted"
     ]
    }
   ],
   "source": [
    "serving.delete(\"IrisFlowerClassifier\")\n",
    "serving.delete(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not serving.exists(\"IrisFlowerClassifier\")\n",
    "assert not serving.exists(\"mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and Numpy helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name    4\n",
      "Age     4\n",
      "dtype: int64"
     ]
    }
   ],
   "source": [
    "from hops import pandas_helper as pandas\n",
    "import pandas as pd\n",
    "\n",
    "lst = ['Geeks', 'For', 'Geeks', 'is', 'portal', 'for', 'Geeks']\n",
    "\n",
    "data = {'Name':['Tom', 'nick', 'krish', 'jack'], 'Age':[20, 21, 19, 18]}\n",
    "\n",
    "data1 = {'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
    "        'Age':[27, 24, 22, 32],\n",
    "        'Address':['Delhi', 'Kanpur', 'Allahabad', 'Kannauj'],\n",
    "        'Qualification':['Msc', 'MA', 'MCA', 'Phd']}\n",
    "\n",
    "pandas_df =  pd.DataFrame(data)\n",
    "pandas.write_csv(\"Resources/team-pandas.csv\", pandas_df)\n",
    "pandas.write_parquet(\"Resources/team-pandas.parquet\", pandas_df)\n",
    "pandas.write_json(\"Resources/team-pandas.json\", pandas_df)\n",
    "\n",
    "test_df = pandas.read_csv(\"Resources/team-pandas.csv\")\n",
    "test_df.count()\n",
    "\n",
    "test_df = pandas.read_json(\"Resources/team-pandas.json\")\n",
    "test_df.count()\n",
    "\n",
    "#test_df = pandas.read_parquet(\"Resources/team-pandas.parquet\")\n",
    "#test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started copying local path numpy-path.npy to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources//numpy-path.npy\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path numpy-path.npz to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources//numpy-path.npz\n",
      "\n",
      "Finished copying\n",
      "\n",
      "Started copying local path numpy-compressed.npz to hdfs path hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources//numpy-compressed.npz\n",
      "\n",
      "Finished copying\n",
      "\n",
      "File hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/numpy-path.npz is already localized, skipping download...\n",
      "File hdfs://10.0.2.15:8020/Projects/demo_deep_learning_admin000/Resources/numpy-compressed.npz is already localized, skipping download...\n",
      "['arr_0', 'arr_1']"
     ]
    }
   ],
   "source": [
    "from hops import numpy_helper as numpy\n",
    "import numpy as np\n",
    "\n",
    "numpy_df = np.array([1, 2, 3])\n",
    "x = np.arange(10)\n",
    "\n",
    "numpy_df.shape\n",
    "\n",
    "numpy.save(\"Resources/numpy-path.npy\", numpy_df)\n",
    "numpy.savez(\"Resources/numpy-path.npz\", numpy_df, x )\n",
    "numpy.savez(\"Resources/numpy-compressed.npz\", numpy_df, x )\n",
    "\n",
    "npzfile = numpy.load(\"Resources/numpy-path.npz\")\n",
    "npzfile.files\n",
    "\n",
    "compressed = numpy.load(\"Resources/numpy-compressed.npz\")\n",
    "compressed.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload REST API tests\n",
    "\n",
    "Test of the UploadService client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hops import project, dataset\n",
    "\n",
    "# Create a a file locally and upload it to the Resources dataset\n",
    "filename = \"test.txt\"\n",
    "lines = 1000000\n",
    "with open(filename, \"w\") as file: # Use file to refer to the file object\n",
    "    text = \"0123456789\\n\" #10 byte string\n",
    "    #write a 1MB rows (~10MB file)\n",
    "    for i in range (0, lines):\n",
    "        file.write(text)\n",
    "\n",
    "# Create API key\n",
    "response = util.send_request(\"POST\", \"/hopsworks-api/api/users/apiKey?name=test-key&scope=DATASET_VIEW&scope=DATASET_CREATE&scope=DATASET_DELETE&scope=PROJECT\")\n",
    "if response.status_code <300:\n",
    "    print(response)\n",
    "    response_body = response.json()\n",
    "    print(response_body)\n",
    "    api_key = response_body['key']\n",
    "    print(api_key)\n",
    "\n",
    "    # Write API key to local file\n",
    "    with open(\"api_key\", \"w\") as file:\n",
    "        file.write(api_key)\n",
    "\n",
    "project.connect(hdfs.project_name(), api_key=\"api_key\")\n",
    "\n",
    "dataset.upload(filename, \"Models\")\n",
    "# Unset this env var so next cells will use JWT\n",
    "if 'API_KEY' in os.environ:\n",
    "    del os.environ['API_KEY']\n",
    "\n",
    "hdfs.copy_to_local(os.path.join(\"Resources\", filename), overwrite=True)\n",
    "# Copy the file from hdfs and assert number of lines\n",
    "assert len(open(filename).readlines(  )) == lines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}